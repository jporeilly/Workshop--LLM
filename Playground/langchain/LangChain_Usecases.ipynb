{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9981c58355f744f899b017a422908836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc645f4584da4c82b563c1ee810463f4",
              "IPY_MODEL_7255b3b22af549a1ab294eee5d211bd2",
              "IPY_MODEL_e8304e0070e1492e9aacac77cf62cca0"
            ],
            "layout": "IPY_MODEL_fce6080ff20e464a82553fc8810f9a75"
          }
        },
        "dc645f4584da4c82b563c1ee810463f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_154408ee77874b229d2d5401c9ef5686",
            "placeholder": "​",
            "style": "IPY_MODEL_f93d1d074f2a4ad889809a9c08a62aed",
            "value": "Downloading readme: 100%"
          }
        },
        "7255b3b22af549a1ab294eee5d211bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6cf0c4d4cb240d1ab99000575c21700",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627efb3a822742f0a8a2b405641133e6",
            "value": 21
          }
        },
        "e8304e0070e1492e9aacac77cf62cca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acbd9f22b4be48b29f334d023d98a1e6",
            "placeholder": "​",
            "style": "IPY_MODEL_7116c01ba20e455d9c863088ea4bf69e",
            "value": " 21.0/21.0 [00:00&lt;00:00, 742B/s]"
          }
        },
        "fce6080ff20e464a82553fc8810f9a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154408ee77874b229d2d5401c9ef5686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f93d1d074f2a4ad889809a9c08a62aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6cf0c4d4cb240d1ab99000575c21700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627efb3a822742f0a8a2b405641133e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acbd9f22b4be48b29f334d023d98a1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7116c01ba20e455d9c863088ea4bf69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "728c76247571491095b62614f0bddbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85ed9eda0f254466b51bf5157b6f7d13",
              "IPY_MODEL_6a458d782fc341bc89a5ca3b214e97e8",
              "IPY_MODEL_bb9d8ed04b4247f2b449996d8c7d7994"
            ],
            "layout": "IPY_MODEL_6944df29e3fa41eda76a8ceff2f00af9"
          }
        },
        "85ed9eda0f254466b51bf5157b6f7d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4cf7e71dac4eeea0c635742335e5f2",
            "placeholder": "​",
            "style": "IPY_MODEL_38647bdd5bc4423995784a4ed4125edb",
            "value": "Downloading data files: 100%"
          }
        },
        "6a458d782fc341bc89a5ca3b214e97e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e1a32ed5ff6453db6e59c93a222d369",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_193b50074f9145b9b822271073830ac8",
            "value": 1
          }
        },
        "bb9d8ed04b4247f2b449996d8c7d7994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_026298650d1d4a69982e28979e73fde2",
            "placeholder": "​",
            "style": "IPY_MODEL_b47892f817d94ed5a5e565ccb7309cb1",
            "value": " 1/1 [00:00&lt;00:00,  3.35it/s]"
          }
        },
        "6944df29e3fa41eda76a8ceff2f00af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4cf7e71dac4eeea0c635742335e5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38647bdd5bc4423995784a4ed4125edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e1a32ed5ff6453db6e59c93a222d369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "193b50074f9145b9b822271073830ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "026298650d1d4a69982e28979e73fde2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47892f817d94ed5a5e565ccb7309cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40b582086d4b49328f85e3f49c7ce9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92fc967f80004f139fce729c3566a934",
              "IPY_MODEL_1d093ce0fbc447aca2b7cfdc67667ce2",
              "IPY_MODEL_002b2f02c04d4eb1ad0e8dca5303ac27"
            ],
            "layout": "IPY_MODEL_5e188f49577341059491ac513ace68c8"
          }
        },
        "92fc967f80004f139fce729c3566a934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a289937dd14ebca1467b075dffe15c",
            "placeholder": "​",
            "style": "IPY_MODEL_25af0c255be84658858473cbfb5d5973",
            "value": "Downloading data: 100%"
          }
        },
        "1d093ce0fbc447aca2b7cfdc67667ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af8493ea70c4a00aed6fb831a991988",
            "max": 1442,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5954df994eb4558a2a966efc4b097e6",
            "value": 1442
          }
        },
        "002b2f02c04d4eb1ad0e8dca5303ac27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc0edc4e9744980928b7d77b0a87f6a",
            "placeholder": "​",
            "style": "IPY_MODEL_42115e44dd554e0f952e681c7308ed43",
            "value": " 1.44k/1.44k [00:00&lt;00:00, 60.6kB/s]"
          }
        },
        "5e188f49577341059491ac513ace68c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a289937dd14ebca1467b075dffe15c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25af0c255be84658858473cbfb5d5973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af8493ea70c4a00aed6fb831a991988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5954df994eb4558a2a966efc4b097e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfc0edc4e9744980928b7d77b0a87f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42115e44dd554e0f952e681c7308ed43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceeb873634e64e258cac67fb0e5f50b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd73f43f101f429ba65e6358562194d2",
              "IPY_MODEL_0ed26fce406d487499a83370c26b27d1",
              "IPY_MODEL_a70e545c187043718093b921af4932c4"
            ],
            "layout": "IPY_MODEL_902df362a35e48d2b4f26f3adca3cbe7"
          }
        },
        "fd73f43f101f429ba65e6358562194d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12e924afd0d649d492328c07088d214e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7b798d76a9247dbad72b99140ccf998",
            "value": "Extracting data files: 100%"
          }
        },
        "0ed26fce406d487499a83370c26b27d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02c1c317dcd45df989cd343cccbd3ed",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_746ceb446b1d4ba09a2a9f89616df4b4",
            "value": 1
          }
        },
        "a70e545c187043718093b921af4932c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87098561b00e4777bbdd17b616d0c8ee",
            "placeholder": "​",
            "style": "IPY_MODEL_45ec202ade6c4e3ab96450718d5e4a21",
            "value": " 1/1 [00:00&lt;00:00, 33.67it/s]"
          }
        },
        "902df362a35e48d2b4f26f3adca3cbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e924afd0d649d492328c07088d214e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b798d76a9247dbad72b99140ccf998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b02c1c317dcd45df989cd343cccbd3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746ceb446b1d4ba09a2a9f89616df4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87098561b00e4777bbdd17b616d0c8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ec202ade6c4e3ab96450718d5e4a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1f2e44c7dd46858199588cad23f79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adc18d8f040b46cea24d4a29d7a53171",
              "IPY_MODEL_740a990ddb614e218c4be2b561168057",
              "IPY_MODEL_b26eeaeb83fd492dbf027c6ca4a3ddb0"
            ],
            "layout": "IPY_MODEL_a680eec5ec0a49fdbad593edbfc94487"
          }
        },
        "adc18d8f040b46cea24d4a29d7a53171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f30eacccbd412badbccbaab11287a7",
            "placeholder": "​",
            "style": "IPY_MODEL_1eea7644514248beb32fe02889ebe8f0",
            "value": "Generating train split: "
          }
        },
        "740a990ddb614e218c4be2b561168057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ddaebbc23f848eb9c5ef093c6337e1a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45ed5c953b8344f5be8ed188e7182982",
            "value": 1
          }
        },
        "b26eeaeb83fd492dbf027c6ca4a3ddb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2668e819554f51a721326327ee51d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7e4fac79594b45b5086304655aab02",
            "value": " 0/0 [00:00&lt;?, ? examples/s]"
          }
        },
        "a680eec5ec0a49fdbad593edbfc94487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "40f30eacccbd412badbccbaab11287a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eea7644514248beb32fe02889ebe8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ddaebbc23f848eb9c5ef093c6337e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "45ed5c953b8344f5be8ed188e7182982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf2668e819554f51a721326327ee51d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7e4fac79594b45b5086304655aab02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b587f6e5eb254e44bba2ccaf288798b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb36817a4dce4e63b7e3916a251be443",
              "IPY_MODEL_0ca848b1e1984ad19ae0e6ace1628277",
              "IPY_MODEL_18ec3afe6cc249f9a99dda3eb9800554"
            ],
            "layout": "IPY_MODEL_e9ef539fb2b34bd3b47e87f077e21391"
          }
        },
        "bb36817a4dce4e63b7e3916a251be443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea04e8dc7d3840efa115556742bbbe01",
            "placeholder": "​",
            "style": "IPY_MODEL_3bdb0a94028d42c6b1af826d9d95ab4b",
            "value": "100%"
          }
        },
        "0ca848b1e1984ad19ae0e6ace1628277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d11bd7eb514329b0b645ced99dd147",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4a9b31c74bb4eeebe0bf4152adb179d",
            "value": 1
          }
        },
        "18ec3afe6cc249f9a99dda3eb9800554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecfa694657074a32bf69f74d22bd6c3c",
            "placeholder": "​",
            "style": "IPY_MODEL_f23b8d06243a4f96ba69c8cd8ea182e0",
            "value": " 1/1 [00:00&lt;00:00, 21.12it/s]"
          }
        },
        "e9ef539fb2b34bd3b47e87f077e21391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea04e8dc7d3840efa115556742bbbe01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bdb0a94028d42c6b1af826d9d95ab4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18d11bd7eb514329b0b645ced99dd147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a9b31c74bb4eeebe0bf4152adb179d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecfa694657074a32bf69f74d22bd6c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23b8d06243a4f96ba69c8cd8ea182e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshan-koirala/youtube-stuffs/blob/main/langchain/LangChain_Usecases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🦜️🔗 LangChain Use Cases 🔑🔎\n",
        "In this notebook, we'll explore 9 different Use cases of LangChain. \n",
        "\n",
        "### [Youtube Video Covering this notebook](https://youtu.be/zS8_qosHNMw)"
      ],
      "metadata": {
        "id": "yTdPFcqYlvTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🦜️🔗 LangChain is a framework for developing applications powered by language models\n"
      ],
      "metadata": {
        "id": "EHm1oFMc12zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🍿 I have already created a video covering [LangChain Components](https://youtu.be/r1HjwBSS80g)   \n",
        "> 📚 LangChain Use Cases official [documentation](https://docs.langchain.com/docs/category/use-cases)"
      ],
      "metadata": {
        "id": "9e5DxrLVfH1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✍️ NOTE from my side:\n",
        "- GPT4 is not being used, mostly, `gpt-3.5-turbo` and `text-davinci-003` are used which are the default models from LangChain based on the specific task we perform.\n",
        "- By no means I am an expert on this topic, I am learning myself and decided to provide this for the community, so most of you get benefit out of it.\n",
        "- For detailed information and documentation, refer to the official [LangChain documentation](https://python.langchain.com/en/latest/index.html)\n",
        "- For more information, you could watch the playlist of [LangChain](https://www.youtube.com/playlist?list=PLz-qytj7eIWVd1a5SsQ1dzOjVDHdgC1Ck) in my youtube channel."
      ],
      "metadata": {
        "id": "GaVlcXo3j0zN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📑🔍 Table of Contents"
      ],
      "metadata": {
        "id": "3-PboxMorLQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[🦜️🔗 LangChain Use Cases 🔑🔎](#scrollTo=yTdPFcqYlvTz)\n",
        "\n",
        ">[📑🔍 Table of Contents](#scrollTo=3-PboxMorLQz)\n",
        "\n",
        ">[⚙️ Setup](#scrollTo=6wL3laYImIY-)\n",
        "\n",
        ">[❓ Question Answering Over Docs](#scrollTo=-7Zn8o9ErrZz)\n",
        "\n",
        ">[💬 Chatbots](#scrollTo=07UooJcX2lDg)\n",
        "\n",
        ">[📚 Querying Tabular Data](#scrollTo=f-OahQD-DVSZ)\n",
        "\n",
        ">[🔌 Interacting with APIs](#scrollTo=ewHeLLxbp_O8)\n",
        "\n",
        ">[📝 Summarization](#scrollTo=7euBT1AOsKbf)\n",
        "\n",
        ">[📤 Extraction](#scrollTo=ISYs1VrbJtwr)\n",
        "\n",
        ">[🧐 Evaluation](#scrollTo=HLKhDE0aQ8QC)\n",
        "\n",
        ">[🤔💻 Code Understanding](#scrollTo=XiQDl7aUQ_Pu)\n",
        "\n",
        ">[🤖 Agents](#scrollTo=XKB1UL04RLP5)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "_F6RfllarBhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚙️ Setup"
      ],
      "metadata": {
        "id": "6wL3laYImIY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EkR21whlkn6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain openai watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "vUvulhuIYRIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -a \"Sudarshan Koirala\" -vmp langchain,openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiCdh2f7X7If",
        "outputId": "91984996-e5de-4851-b4c0-8f87e159b81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Sudarshan Koirala\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.11\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "langchain: 0.0.165\n",
            "openai   : 0.27.6\n",
            "\n",
            "Compiler    : GCC 9.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.10.147+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get your openai api key from https://platform.openai.com/account/api-keys 🔑\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utbIcWyJg3lB",
        "outputId": "7b561a02-8ba8-44e5-85b8-6d08f8fb1819"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "w3C_E0-Wh0Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- In my earlier videos in the [LangChain Series](https://www.youtube.com/playlist?list=PLz-qytj7eIWVd1a5SsQ1dzOjVDHdgC1Ck), I have demostrated how you can integrate the use case using [Streamlit](https://streamlit.io/) and [Gradio](https://www.gradio.app/). \n",
        "- In this case, I will just go through the use-case as it is in the notebook, you could integrate it into app like feeling referring to the earlier videos. 🙏"
      ],
      "metadata": {
        "id": "xalCXYnLreV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. [ ❓ Question Answering Over Docs](https://docs.langchain.com/docs/use-cases/qa-docs) \n",
        "- [Chat With Any CSV](https://youtu.be/ZwxdQB9HjTU), [Chat with Multiple Documents](https://youtu.be/TeDgIDqQmzs), [Chat with Any Pdf](https://youtu.be/edQzdkrDRGM)"
      ],
      "metadata": {
        "id": "-7Zn8o9ErrZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normally simple things are over shadowed :)\n",
        "\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "pnW5taM7qMJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()"
      ],
      "metadata": {
        "id": "Xc5mBCtI1CJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"who is from Nepal ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Wgt29VUB1_f7",
        "outputId": "94f30afa-878c-41c0-89c4-f297c0b9d447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nNepalis are people who are from Nepal.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "Sudarshan is from Nepal.\n",
        "Ashish is from India.\n",
        "Mikko is from Finland.\n",
        "Khoa is from Vietnam.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Who is from Nepal ?\""
      ],
      "metadata": {
        "id": "d-GwMYdv1Q1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm(context + question)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydC7-C9216fP",
        "outputId": "95ef3c21-814e-416a-ae5b-b8dff4d3f800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sudarshan is from Nepal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. [ 💬 Chatbots](https://docs.langchain.com/docs/use-cases/chatbots)\n",
        "ChatGPT is one of the chatbot so you know what it is already. They are oftern very powerful when combined with other sources of data.\n",
        "- [Chat With Any CSV](https://youtu.be/ZwxdQB9HjTU), [Chat with Multiple Documents](https://youtu.be/TeDgIDqQmzs), [Chat with Any Pdf](https://youtu.be/edQzdkrDRGM)\n",
        "- In this example, lets create a ChatGPT Clone"
      ],
      "metadata": {
        "id": "07UooJcX2lDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "\n",
        "template = \"\"\"\n",
        "You are an assistant trained by OpenAI.\n",
        "Your goal is to provide help just with foods.\n",
        "Don't provide answer other than food related topics. \n",
        "Just output \"I don't know\" if other topics are asked.\n",
        "\n",
        "{history}\n",
        "Human: {human_input}\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"human_input\"], \n",
        "    template=template)\n",
        "\n",
        "\n",
        "chatgpt_chain = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferWindowMemory(memory_key=\"history\"),\n",
        ")\n",
        "\n",
        "output = chatgpt_chain.predict(\n",
        "    human_input=\"What is Python?\"\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JcvSLnpO2W4N",
        "outputId": "2444cae0-c591-424d-d6a6-1e44cebc1747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Your are an assistant trained by OpenAI.\n",
            "Your goal is to provide help just with foods.\n",
            "Don't provide answer other than food related topics. \n",
            "Just output \"I don't know\" if other topics are asked.\n",
            "\n",
            "\n",
            "Human: What is Python?\n",
            "Assistant:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = chatgpt_chain.predict(human_input=\"Which fruit is better, apple or orange ?\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "zV6MP9TX6A87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "a9c02379-a428-441e-e957-add4b5cd150a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Your are an assistant trained by OpenAI.\n",
            "Your goal is to provide help just with foods.\n",
            "Don't provide answer other than food related topics. \n",
            "Just output \"I don't know\" if other topics are asked.\n",
            "\n",
            "Human: What is Python?\n",
            "AI:  I don't know.\n",
            "Human: Which fruit is better, apple or orange ?\n",
            "Assistant:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Apples are a good source of fiber, vitamins, and antioxidants, while oranges are a good source of vitamin C, folate, and potassium.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = chatgpt_chain.predict(human_input=\"What about apple and samsung ?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "yveRu0sG_MCy",
        "outputId": "ccc31a8e-4dc4-47c9-e5a7-667fc63179aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Your are an assistant trained by OpenAI.\n",
            "Your goal is to provide help just with foods.\n",
            "Don't provide answer other than food related topics. \n",
            "Just output \"I don't know\" if other topics are asked.\n",
            "\n",
            "Human: What is Python?\n",
            "AI:  I don't know.\n",
            "Human: Which fruit is better, apple or orange ?\n",
            "AI:  Apples are a good source of fiber, vitamins, and antioxidants, while oranges are a good source of vitamin C, folate, and potassium.\n",
            "Human: What about apple and samsung ?\n",
            "Assistant:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = chatgpt_chain.predict(human_input=\"What is the first question I asked you ?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "BQ_by5VpAxk6",
        "outputId": "458102d7-1f0b-41b2-bfd7-1b3f9b02a832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Your are an assistant trained by OpenAI.\n",
            "Your goal is to provide help just with foods.\n",
            "Don't provide answer other than food related topics. \n",
            "Just output \"I don't know\" if other topics are asked.\n",
            "\n",
            "Human: What is Python?\n",
            "AI:  I don't know.\n",
            "Human: Which fruit is better, apple or orange ?\n",
            "AI:  Apples are a good source of fiber, vitamins, and antioxidants, while oranges are a good source of vitamin C, folate, and potassium.\n",
            "Human: What about apple and samsung ?\n",
            "AI:  I don't know.\n",
            "Human: What is the first question I asked you ?\n",
            "Assistant:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " What is Python?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. [ 📚 Querying Tabular Data](https://python.langchain.com/en/latest/use_cases/tabular.html)\n",
        "- Earlier video in this topic: [ChatCSV: Chat With Any CSV](https://youtu.be/ZwxdQB9HjTU)\n",
        "- I covered `CSV Agent` and `Pandas Agent` befor, lets go through the `SQL Agent`.\n",
        "- [SQL Chain example from langchain](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html)"
      ],
      "metadata": {
        "id": "f-OahQD-DVSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "73O0dQOkU1P2",
        "outputId": "e091acf2-bdf7-4a2e-bfd8-e3ff1fdca9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqlite_db_path = \"/content/Chinook.db\"\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\n",
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ldWx4aB4XD8_",
        "outputId": "93f4a568-a9fb-493b-de2e-20e9673c9bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_chain = SQLDatabaseChain.from_llm(llm=llm, database=db, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0A41nUHzaA18",
        "outputId": "044d32de-99aa-47e3-ea6d-3cb4697272d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_chain.run(\"How many employees are there?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "dX8ei2TdaEWi",
        "outputId": "2010c8ec-30dc-4b99-ecbe-ad25ef68c43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "How many employees are there?\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT COUNT(*) FROM \"Employee\";\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(8,)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3m There are 8 employees.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' There are 8 employees.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WOW! Natural Language to Natural Langauge. But quite a things went on there if you observe closely."
      ],
      "metadata": {
        "id": "uSzo3xFTbyla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returning the intermediate steps."
      ],
      "metadata": {
        "id": "J5GYwK06enWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_chain = SQLDatabaseChain.from_llm(llm, db, return_intermediate_steps=True, verbose=True)\n",
        "result = db_chain(\"How many employees are there?\")\n",
        "result['intermediate_steps']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "XGfqjrQqaHEg",
        "outputId": "089e7e86-82ae-4cc5-91db-9f727a7ec371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "How many employees are there?\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT COUNT(*) FROM \"Employee\";\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(8,)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3m There are 8 employees.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' SELECT COUNT(*) FROM \"Employee\";', '[(8,)]']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. [ 🔌 Interacting with APIs](https://docs.langchain.com/docs/use-cases/apis)\n",
        "- APIs are powerful because if you need to perform some action or talk to data from behind an API, we need LLM to interact with it.\n",
        "- Lets go through on example using [Open-Meteo](https://open-meteo.com/) which is a free weather api.\n",
        "- Open-Meteo is an open-source weather API with free access for non-commercial use. No API key is required."
      ],
      "metadata": {
        "id": "ewHeLLxbp_O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import APIChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "Gn4LtIqJfVzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.api import open_meteo_docs\n",
        "chain_new = APIChain.from_llm_and_api_docs(llm, open_meteo_docs.OPEN_METEO_DOCS, verbose=True)"
      ],
      "metadata": {
        "id": "lOdytpIArkoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_new.run('What is the weather like right now in Helsinki, Finlnad in degrees Celsius?')"
      ],
      "metadata": {
        "id": "hk0uaaI1rzVi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "db0f8c53-e4f4-4763-f4b0-7439ac3aebe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mhttps://api.open-meteo.com/v1/forecast?latitude=60.17&longitude=24.94&hourly=temperature_2m&current_weather=true&temperature_unit=celsius\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m{\"latitude\":60.16998,\"longitude\":24.94519,\"generationtime_ms\":0.164031982421875,\"utc_offset_seconds\":0,\"timezone\":\"GMT\",\"timezone_abbreviation\":\"GMT\",\"elevation\":7.0,\"current_weather\":{\"temperature\":18.1,\"windspeed\":10.4,\"winddirection\":230.0,\"weathercode\":0,\"is_day\":1,\"time\":\"2023-05-12T17:00\"},\"hourly_units\":{\"time\":\"iso8601\",\"temperature_2m\":\"°C\"},\"hourly\":{\"time\":[\"2023-05-12T00:00\",\"2023-05-12T01:00\",\"2023-05-12T02:00\",\"2023-05-12T03:00\",\"2023-05-12T04:00\",\"2023-05-12T05:00\",\"2023-05-12T06:00\",\"2023-05-12T07:00\",\"2023-05-12T08:00\",\"2023-05-12T09:00\",\"2023-05-12T10:00\",\"2023-05-12T11:00\",\"2023-05-12T12:00\",\"2023-05-12T13:00\",\"2023-05-12T14:00\",\"2023-05-12T15:00\",\"2023-05-12T16:00\",\"2023-05-12T17:00\",\"2023-05-12T18:00\",\"2023-05-12T19:00\",\"2023-05-12T20:00\",\"2023-05-12T21:00\",\"2023-05-12T22:00\",\"2023-05-12T23:00\",\"2023-05-13T00:00\",\"2023-05-13T01:00\",\"2023-05-13T02:00\",\"2023-05-13T03:00\",\"2023-05-13T04:00\",\"2023-05-13T05:00\",\"2023-05-13T06:00\",\"2023-05-13T07:00\",\"2023-05-13T08:00\",\"2023-05-13T09:00\",\"2023-05-13T10:00\",\"2023-05-13T11:00\",\"2023-05-13T12:00\",\"2023-05-13T13:00\",\"2023-05-13T14:00\",\"2023-05-13T15:00\",\"2023-05-13T16:00\",\"2023-05-13T17:00\",\"2023-05-13T18:00\",\"2023-05-13T19:00\",\"2023-05-13T20:00\",\"2023-05-13T21:00\",\"2023-05-13T22:00\",\"2023-05-13T23:00\",\"2023-05-14T00:00\",\"2023-05-14T01:00\",\"2023-05-14T02:00\",\"2023-05-14T03:00\",\"2023-05-14T04:00\",\"2023-05-14T05:00\",\"2023-05-14T06:00\",\"2023-05-14T07:00\",\"2023-05-14T08:00\",\"2023-05-14T09:00\",\"2023-05-14T10:00\",\"2023-05-14T11:00\",\"2023-05-14T12:00\",\"2023-05-14T13:00\",\"2023-05-14T14:00\",\"2023-05-14T15:00\",\"2023-05-14T16:00\",\"2023-05-14T17:00\",\"2023-05-14T18:00\",\"2023-05-14T19:00\",\"2023-05-14T20:00\",\"2023-05-14T21:00\",\"2023-05-14T22:00\",\"2023-05-14T23:00\",\"2023-05-15T00:00\",\"2023-05-15T01:00\",\"2023-05-15T02:00\",\"2023-05-15T03:00\",\"2023-05-15T04:00\",\"2023-05-15T05:00\",\"2023-05-15T06:00\",\"2023-05-15T07:00\",\"2023-05-15T08:00\",\"2023-05-15T09:00\",\"2023-05-15T10:00\",\"2023-05-15T11:00\",\"2023-05-15T12:00\",\"2023-05-15T13:00\",\"2023-05-15T14:00\",\"2023-05-15T15:00\",\"2023-05-15T16:00\",\"2023-05-15T17:00\",\"2023-05-15T18:00\",\"2023-05-15T19:00\",\"2023-05-15T20:00\",\"2023-05-15T21:00\",\"2023-05-15T22:00\",\"2023-05-15T23:00\",\"2023-05-16T00:00\",\"2023-05-16T01:00\",\"2023-05-16T02:00\",\"2023-05-16T03:00\",\"2023-05-16T04:00\",\"2023-05-16T05:00\",\"2023-05-16T06:00\",\"2023-05-16T07:00\",\"2023-05-16T08:00\",\"2023-05-16T09:00\",\"2023-05-16T10:00\",\"2023-05-16T11:00\",\"2023-05-16T12:00\",\"2023-05-16T13:00\",\"2023-05-16T14:00\",\"2023-05-16T15:00\",\"2023-05-16T16:00\",\"2023-05-16T17:00\",\"2023-05-16T18:00\",\"2023-05-16T19:00\",\"2023-05-16T20:00\",\"2023-05-16T21:00\",\"2023-05-16T22:00\",\"2023-05-16T23:00\",\"2023-05-17T00:00\",\"2023-05-17T01:00\",\"2023-05-17T02:00\",\"2023-05-17T03:00\",\"2023-05-17T04:00\",\"2023-05-17T05:00\",\"2023-05-17T06:00\",\"2023-05-17T07:00\",\"2023-05-17T08:00\",\"2023-05-17T09:00\",\"2023-05-17T10:00\",\"2023-05-17T11:00\",\"2023-05-17T12:00\",\"2023-05-17T13:00\",\"2023-05-17T14:00\",\"2023-05-17T15:00\",\"2023-05-17T16:00\",\"2023-05-17T17:00\",\"2023-05-17T18:00\",\"2023-05-17T19:00\",\"2023-05-17T20:00\",\"2023-05-17T21:00\",\"2023-05-17T22:00\",\"2023-05-17T23:00\",\"2023-05-18T00:00\",\"2023-05-18T01:00\",\"2023-05-18T02:00\",\"2023-05-18T03:00\",\"2023-05-18T04:00\",\"2023-05-18T05:00\",\"2023-05-18T06:00\",\"2023-05-18T07:00\",\"2023-05-18T08:00\",\"2023-05-18T09:00\",\"2023-05-18T10:00\",\"2023-05-18T11:00\",\"2023-05-18T12:00\",\"2023-05-18T13:00\",\"2023-05-18T14:00\",\"2023-05-18T15:00\",\"2023-05-18T16:00\",\"2023-05-18T17:00\",\"2023-05-18T18:00\",\"2023-05-18T19:00\",\"2023-05-18T20:00\",\"2023-05-18T21:00\",\"2023-05-18T22:00\",\"2023-05-18T23:00\"],\"temperature_2m\":[12.2,11.7,10.9,9.9,11.4,12.7,13.7,15.4,16.7,17.6,18.4,18.9,19.2,19.4,19.5,19.3,18.6,18.1,19.1,18.2,16.7,15.7,15.0,13.9,12.6,11.6,11.0,10.9,12.3,14.4,16.0,15.2,16.0,16.6,17.0,17.5,17.6,17.7,17.5,16.9,16.7,16.7,17.3,17.2,17.2,16.4,15.5,14.7,14.0,13.4,13.1,13.2,13.1,14.1,14.8,16.4,18.6,20.5,20.1,18.8,18.5,18.2,18.3,17.4,16.7,15.5,15.2,13.4,12.9,11.9,11.6,10.9,10.4,10.2,7.6,7.8,8.5,9.7,11.0,12.0,12.4,12.8,13.4,14.2,14.5,14.4,14.2,14.5,14.3,12.9,11.8,11.1,10.5,9.9,9.9,10.1,10.4,10.4,10.3,10.4,10.8,11.3,12.1,12.6,13.2,13.7,13.7,13.4,13.0,12.7,12.4,12.0,11.8,11.7,11.5,11.2,10.9,10.5,10.3,10.2,10.1,10.0,9.9,10.0,10.2,10.4,10.7,10.7,10.6,10.7,11.3,12.2,13.0,12.8,13.0,12.9,12.6,12.1,11.2,10.3,9.2,7.9,7.1,6.4,5.6,5.0,4.5,4.5,5.6,7.2,9.2,10.3,11.3,12.2,12.2,11.8,11.3,11.2,11.1,10.8,10.2,9.6,8.8,8.4,8.1,7.8,7.6,7.5]}}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The current temperature in Helsinki, Finland is 18.1°C.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. [ 📝 Summarization](https://python.langchain.com/en/latest/use_cases/summarization.html)\n",
        "- Creating smaller summary from longer documents.\n",
        "- Refer to earlier video about [PDFSummarization](https://youtu.be/iMDBMTFT0ns)\n",
        "- There are different [chain types](https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html) \n",
        "- Many ways how you can [interact with PDF](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html).\n",
        "- Summarization can be done from couple of sentences to entire book."
      ],
      "metadata": {
        "id": "7euBT1AOsKbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "0AlcLTwlD0_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paragraph summarization\n",
        "from langchain import OpenAI\n",
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "u23b4SVmDBG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Please provide a summary of the following text.\n",
        "Provide answer in simple terms and max lenght of 30 words.\n",
        "\n",
        "TEXT:\n",
        "A common use case is wanting to summarize long documents. This naturally runs into \\\n",
        "the context window limitations. Unlike in question-answering, you can't just do some \\\n",
        "semantic search hacks to only select the chunks of text most relevant to the question \\\n",
        "(because, in this case, there is no particular question - you want to summarize everything). So what do you do then?\n",
        "\n",
        "The most common way around this is to split the documents into chunks and then do \\\n",
        "summarization in a recursive manner. By this we mean you first summarize each chunk \\\n",
        "by itself, then you group the summaries into chunks and summarize each chunk of summaries, and continue doing that until only one is left.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Se0sqR58DT7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = llm.get_num_tokens(prompt)\n",
        "print (f\"Our prompt has {num_tokens} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhPzTdsuDtuy",
        "outputId": "2bdd3bea-1340-4e3a-a29e-4e131b991875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our prompt has 170 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = llm(prompt)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hifbH-R_Dxde",
        "outputId": "a04360e2-a488-4ba1-cdf1-681120f3f6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summarize long documents by splitting them into chunks and summarizing each chunk recursively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "_3v0a0-4-x6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "Sjja8u9kGx8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the pdf \n",
        "!wget https://static.nomic.ai/gpt4all/2023_GPT4All-J_Technical_Report_2.pdf -O gpt4all-j.pdf"
      ],
      "metadata": {
        "id": "tdBXrBcZJf-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader('/content/gpt4all-j.pdf')\n",
        "doc=loader.load_and_split()"
      ],
      "metadata": {
        "id": "coFxL3R-HM1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "chain.run(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Y-1H2DgEEBgw",
        "outputId": "748ee803-0e5f-4788-9597-b940db81705e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This paper presents GPT4All-J, a model trained on a large corpus of assistant interactions, including word problems, multi-turn dialogue, code, poems, songs, and stories. It is evaluated against other models on common sense reasoning tasks and outperforms them with a ground truth perplexity of 0.18 metric tons of carbon dioxide. The data, training code, and model weights are released under an Apache 2 license to accelerate open LLM research.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. [ 📤 Extraction](https://python.langchain.com/en/latest/use_cases/evaluation.html)\n",
        "- Extracting something.\n",
        "- Extraction is related to [output parsing](https://python.langchain.com/en/latest/modules/prompts/output_parsers.html) which are responsible for instructing LLMs to respond in a specific format.\n",
        "- For deep dive, LangChain recommends checking [kor](https://eyurtsev.github.io/kor/index.html) library which uses LangChain chain and OutputParser abstrations but allows deep dives on allowing extraction of more complicated schemas."
      ],
      "metadata": {
        "id": "ISYs1VrbJtwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To help construct our Chat Messages\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# We will be using a chat model, defaults to gpt-3.5-turbo\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# To parse outputs and get structured data back\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "\n",
        "chat_model = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "u7Nbgjn-G4YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"\"\"\n",
        "Given a random sentence which contains animals name, extract animal names and assign an emoji to that and return just the animal name with emoji.\n",
        "\"\"\"\n",
        "\n",
        "animal_names = \"\"\"\n",
        "Dog, cat and rabbit are in the garden.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JBwomLBtM9rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (instructions + animal_names)\n",
        "output = chat_model([HumanMessage(content=prompt)])\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4VrUSFANwHZ",
        "outputId": "052a6f0e-94b5-4d3c-a523-bbc43b76e7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🐶 Dog, 🐱 cat and 🐰 rabbit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go through one example from kor too.\n",
        "> Kor is a thin wrapper on top of LLMs that helps to extract structured data using LLMs."
      ],
      "metadata": {
        "id": "Qxn3mxc2PnCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kor"
      ],
      "metadata": {
        "id": "WSlrsSFjN1rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kor.extraction import create_extraction_chain\n",
        "from kor.nodes import Object, Text, Number\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "L2BdO40XPv6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# schema\n",
        "schema = Object(\n",
        "    id=\"person\",\n",
        "    description=\"Personal information\",\n",
        "    examples=[\n",
        "        (\"Alice and Bob are friends\", [{\"first_name\": \"Alice\"}, {\"first_name\": \"Bob\"}])\n",
        "    ],\n",
        "    attributes=[\n",
        "        Text(\n",
        "            id=\"first_name\",\n",
        "            description=\"The first name of a person.\",\n",
        "        )\n",
        "    ],\n",
        "    many=True,\n",
        ")"
      ],
      "metadata": {
        "id": "enpTei7dP7Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate a langchain llm and create a chain\n",
        "llm = ChatOpenAI()\n",
        "chain = create_extraction_chain(llm, schema)"
      ],
      "metadata": {
        "id": "Kh9gGbsTQCSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract\n",
        "chain.predict_and_parse(text=(\"My name is Bobby. My brother's name Joe. My another brother's name is Stephen\"))[\"data\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzOpCPBKQP3d",
        "outputId": "dee5489d-3783-4bad-8276-78516545a314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'person': [{'first_name': 'Bobby'},\n",
              "  {'first_name': 'Joe'},\n",
              "  {'first_name': 'Stephen'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. [ 🧐 Evaluation](https://python.langchain.com/en/latest/use_cases/evaluation.html)\n",
        "- Evaluation after creating chains/agents internally as well as application building on top of Langchain is necessary.\n",
        "- Lack of data and lack of metrics are the key issues. \n",
        "- How LangChain is tackling this and will improve:\n",
        "    - For lack of data, there is a [LangChainDatasets](https://huggingface.co/LangChainDatasets) in Hugging Face.\n",
        "    - For lack of metrics, using no metrics, meaing just relying on the output and doing human observation. Next is using [tracing](https://python.langchain.com/en/latest/tracing.html), a UI-based visualizer of your chain and agent runs.\n",
        "    - As we went through the SQL querying in the Tabular Data part, lets use the [SQL Question Answering Benchmarking: Chinook](https://python.langchain.com/en/latest/tracing.html)"
      ],
      "metadata": {
        "id": "HLKhDE0aQ8QC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the data**"
      ],
      "metadata": {
        "id": "Kp_YS0A5ukV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.loading import load_dataset\n",
        "dataset = load_dataset(\"sql-qa-chinook\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "RHBPxLHnjCJf",
        "outputId": "0dc7b517-9bec-466e-a38f-17e1fff6e44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-90e2e157f024>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sql-qa-chinook\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/evaluation/loading.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"LangChainDatasets/{uri}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "claxuw-zteWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data\n",
        "from langchain.evaluation.loading import load_dataset\n",
        "dataset = load_dataset(\"sql-qa-chinook\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "9981c58355f744f899b017a422908836",
            "dc645f4584da4c82b563c1ee810463f4",
            "7255b3b22af549a1ab294eee5d211bd2",
            "e8304e0070e1492e9aacac77cf62cca0",
            "fce6080ff20e464a82553fc8810f9a75",
            "154408ee77874b229d2d5401c9ef5686",
            "f93d1d074f2a4ad889809a9c08a62aed",
            "c6cf0c4d4cb240d1ab99000575c21700",
            "627efb3a822742f0a8a2b405641133e6",
            "acbd9f22b4be48b29f334d023d98a1e6",
            "7116c01ba20e455d9c863088ea4bf69e",
            "728c76247571491095b62614f0bddbf9",
            "85ed9eda0f254466b51bf5157b6f7d13",
            "6a458d782fc341bc89a5ca3b214e97e8",
            "bb9d8ed04b4247f2b449996d8c7d7994",
            "6944df29e3fa41eda76a8ceff2f00af9",
            "2c4cf7e71dac4eeea0c635742335e5f2",
            "38647bdd5bc4423995784a4ed4125edb",
            "2e1a32ed5ff6453db6e59c93a222d369",
            "193b50074f9145b9b822271073830ac8",
            "026298650d1d4a69982e28979e73fde2",
            "b47892f817d94ed5a5e565ccb7309cb1",
            "40b582086d4b49328f85e3f49c7ce9f0",
            "92fc967f80004f139fce729c3566a934",
            "1d093ce0fbc447aca2b7cfdc67667ce2",
            "002b2f02c04d4eb1ad0e8dca5303ac27",
            "5e188f49577341059491ac513ace68c8",
            "16a289937dd14ebca1467b075dffe15c",
            "25af0c255be84658858473cbfb5d5973",
            "3af8493ea70c4a00aed6fb831a991988",
            "a5954df994eb4558a2a966efc4b097e6",
            "dfc0edc4e9744980928b7d77b0a87f6a",
            "42115e44dd554e0f952e681c7308ed43",
            "ceeb873634e64e258cac67fb0e5f50b9",
            "fd73f43f101f429ba65e6358562194d2",
            "0ed26fce406d487499a83370c26b27d1",
            "a70e545c187043718093b921af4932c4",
            "902df362a35e48d2b4f26f3adca3cbe7",
            "12e924afd0d649d492328c07088d214e",
            "e7b798d76a9247dbad72b99140ccf998",
            "b02c1c317dcd45df989cd343cccbd3ed",
            "746ceb446b1d4ba09a2a9f89616df4b4",
            "87098561b00e4777bbdd17b616d0c8ee",
            "45ec202ade6c4e3ab96450718d5e4a21",
            "ec1f2e44c7dd46858199588cad23f79c",
            "adc18d8f040b46cea24d4a29d7a53171",
            "740a990ddb614e218c4be2b561168057",
            "b26eeaeb83fd492dbf027c6ca4a3ddb0",
            "a680eec5ec0a49fdbad593edbfc94487",
            "40f30eacccbd412badbccbaab11287a7",
            "1eea7644514248beb32fe02889ebe8f0",
            "8ddaebbc23f848eb9c5ef093c6337e1a",
            "45ed5c953b8344f5be8ed188e7182982",
            "bf2668e819554f51a721326327ee51d6",
            "6d7e4fac79594b45b5086304655aab02",
            "b587f6e5eb254e44bba2ccaf288798b8",
            "bb36817a4dce4e63b7e3916a251be443",
            "0ca848b1e1984ad19ae0e6ace1628277",
            "18ec3afe6cc249f9a99dda3eb9800554",
            "e9ef539fb2b34bd3b47e87f077e21391",
            "ea04e8dc7d3840efa115556742bbbe01",
            "3bdb0a94028d42c6b1af826d9d95ab4b",
            "18d11bd7eb514329b0b645ced99dd147",
            "c4a9b31c74bb4eeebe0bf4152adb179d",
            "ecfa694657074a32bf69f74d22bd6c3c",
            "f23b8d06243a4f96ba69c8cd8ea182e0"
          ]
        },
        "id": "8gjFl2jittoh",
        "outputId": "41811fa2-affd-4a35-fc50-02f4e2ba28a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9981c58355f744f899b017a422908836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset json/LangChainDatasets--sql-qa-chinook to /root/.cache/huggingface/datasets/LangChainDatasets___json/LangChainDatasets--sql-qa-chinook-7528565d2d992b47/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "728c76247571491095b62614f0bddbf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40b582086d4b49328f85e3f49c7ce9f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceeb873634e64e258cac67fb0e5f50b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec1f2e44c7dd46858199588cad23f79c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/LangChainDatasets___json/LangChainDatasets--sql-qa-chinook-7528565d2d992b47/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b587f6e5eb254e44bba2ccaf288798b8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIV0auiOtz-8",
        "outputId": "591343db-4fad-400a-8efb-47c9d573f6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '8', 'question': 'How many employees are there?'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up a Chain**"
      ],
      "metadata": {
        "id": "WgnsKgpUudD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain"
      ],
      "metadata": {
        "id": "4wdI6CuBt76k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqlite_db_path = \"/content/Chinook.db\"\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\n",
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "j8bS5ytCuDYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sql database chain\n",
        "chain = SQLDatabaseChain(llm=llm, database=db, input_key=\"question\")"
      ],
      "metadata": {
        "id": "YglGGKDiuFDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a prediction**"
      ],
      "metadata": {
        "id": "hmXGD0cvuraT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import sqlite3\n",
        "# doing just one prediction to check\n",
        "chain(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2op99uouFWJ",
        "outputId": "68b0fe4d-90bf-4f7a-8415-cc6367921c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '8',\n",
              " 'question': 'How many employees are there?',\n",
              " 'result': ' There are 8 employees.'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bulk predictions\n",
        "predictions = []\n",
        "predicted_dataset = []\n",
        "error_dataset = []\n",
        "for data in dataset:\n",
        "    try:\n",
        "        predictions.append(chain(data))\n",
        "        predicted_dataset.append(data)\n",
        "    except:\n",
        "        error_dataset.append(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzXmH4vZuF4P",
        "outputId": "6a647a45-b07a-41b6-b257-8e8ad4fdd82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the performance**"
      ],
      "metadata": {
        "id": "mYmUmrB9yY1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.qa import QAEvalChain\n",
        "llm = OpenAI(temperature=0)\n",
        "eval_chain = QAEvalChain.from_llm(llm)\n",
        "graded_outputs = eval_chain.evaluate(predicted_dataset, predictions, question_key=\"question\", prediction_key=\"result\")"
      ],
      "metadata": {
        "id": "vdLNhpsIyVb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding graded output to preditions dict\n",
        "for i, prediction in enumerate(predictions):\n",
        "    prediction['grade'] = graded_outputs[i]['text']"
      ],
      "metadata": {
        "id": "tzKOSZ95yVPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now getting a count of the grades\n",
        "from collections import Counter\n",
        "Counter([pred['grade'] for pred in predictions])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--yqHVpSyVFa",
        "outputId": "8d3576d7-e331-4669-e9a2-5996a1bb9773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({' CORRECT': 3, ' INCORRECT': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter datapoints to the incorrect examples\n",
        "incorrect = [pred for pred in predictions if pred['grade'] == \" INCORRECT\"]\n",
        "incorrect[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbZkoxiYz3HC",
        "outputId": "40ce51b3-d3b0-410c-db9d-9748b1c0d68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'None',\n",
              " 'question': 'How many employees are also customers?',\n",
              " 'result': ' 59 employees are also customers.',\n",
              " 'grade': ' INCORRECT'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. [ 🤔💻 Code Understanding](https://python.langchain.com/en/latest/use_cases/code.html)\n",
        "- LLMs are good at code understanding. I hope you are already using it to creat code based on your query. For example, in ChatGPT and similar chatbots. You might have heard about [copilot](https://github.com/features/copilot)\n",
        "- LangChain is a useful tool designed to parse the GitHub code repositories.\n",
        "- Let's use [pandas-ai](https://github.com/gventuri/pandas-ai)"
      ],
      "metadata": {
        "id": "XiQDl7aUQ_Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gventuri/pandas-ai.git # replace any repository of your choice "
      ],
      "metadata": {
        "id": "hzgIxxNUF6dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.vectorstores import Chroma, FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "xR6ku1Ge_ZFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(disallowed_special=())"
      ],
      "metadata": {
        "id": "EZC1qf8N_Zo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "root_dir = '/content/pandas-ai'\n",
        "docs = []\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for file in filenames:\n",
        "        try: \n",
        "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "            docs.extend(loader.load_and_split())\n",
        "        except Exception as e: \n",
        "            pass"
      ],
      "metadata": {
        "id": "PkeuNXTP_Z_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"You have {len(docs)} documents\\n\")\n",
        "print(\"------ Start Document ------\")\n",
        "print(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JixB-MuWF071",
        "outputId": "eff7bf71-0879-47d7-9b84-6b4ec4b46147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 142 documents\n",
            "\n",
            "------ Start Document ------\n",
            "page_content='# PandasAI 🐼\\n\\n[![release](https://img.shields.io/pypi/v/pandasai?label=Release&style=flat-square)](https://pypi.org/project/pandasai/)\\n[![lint](https://github.com/gventuri/pandas-ai/actions/workflows/ci.yml/badge.svg)](https://github.com/gventuri/pandas-ai/actions/workflows/ci.yml/badge.svg)\\n[![](https://dcbadge.vercel.app/api/server/kF7FqH2FwS?style=flat&compact=true)](https://discord.gg/kF7FqH2FwS)\\n[![Downloads](https://static.pepy.tech/badge/pandasai/month)](https://pepy.tech/project/pandasai) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n[![Open in Colab](https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1rKz7TudOeCeKGHekw7JFNL4sagN9hon-?usp=sharing)\\n\\nPandas AI is a Python library that adds generative artificial intelligence capabilities to Pandas, the popular data analysis and manipulation tool. It is designed to be used in conjunction with Pandas, and is not a replacement for it.\\n\\n<!-- Add images/pandas-ai.png -->\\n\\n![PandasAI](images/pandas-ai.png?raw=true)\\n\\n## Demo\\n\\nTry out PandasAI in your browser:\\n\\n[![Open in Colab](https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1rKz7TudOeCeKGHekw7JFNL4sagN9hon-?usp=sharing)\\n\\n## Installation\\n\\n```bash\\npip install pandasai\\n```\\n\\n## Usage\\n\\n> Disclaimer: GDP data was collected from [this source](https://ourworldindata.org/grapher/gross-domestic-product?tab=table), published by World Development Indicators - World Bank (2022.05.26) and collected at National accounts data - World Bank / OECD. It relates to the year of 2020. Happiness indexes were extracted from [the World Happiness Report](https://ftnnews.com/images/stories/documents/2020/WHR20.pdf). Another useful [link](https://data.world/makeovermonday/2020w19-world-happiness-report-2020).\\n\\nPandasAI is designed to be used in conjunction with Pandas. It makes Pandas conversational, allowing you to ask questions about your data and get answers back, in the form of Pandas DataFrames. For example, you can ask PandasAI to find all the rows in a DataFrame where the value of a column is greater than 5, and it will return a DataFrame containing only those rows:\\n\\n```python\\nimport pandas as pd\\nfrom pandasai import PandasAI\\n\\n# Sample DataFrame\\ndf = pd.DataFrame({\\n    \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Italy\", \"Spain\", \"Canada\", \"Australia\", \"Japan\", \"China\"],\\n    \"gdp\": [19294482071552, 2891615567872, 2411255037952, 3435817336832, 1745433788416, 1181205135360, 1607402389504, 1490967855104, 4380756541440, 14631844184064],\\n    \"happiness_index\": [6.94, 7.16, 6.66, 7.07, 6.38, 6.4, 7.23, 7.22, 5.87, 5.12]\\n})\\n\\n# Instantiate a LLM\\nfrom pandasai.llm.openai import OpenAI\\nllm = OpenAI()\\n\\npandas_ai = PandasAI(llm)\\npandas_ai.run(df, prompt=\\'Which are the 5 happiest countries?\\')\\n```\\n\\nThe above code will return the following:\\n\\n```\\n6            Canada\\n7         Australia\\n1    United Kingdom\\n3           Germany\\n0     United States\\nName: country, dtype: object\\n```\\n\\nOf course, you can also ask PandasAI to perform more complex queries. For example, you can ask PandasAI to find the sum of the GDPs of the 2 unhappiest countries:\\n\\n```python\\npandas_ai.run(df, prompt=\\'What is the sum of the GDPs of the 2 unhappiest countries?\\')\\n```\\n\\nThe above code will return the following:\\n\\n```\\n19012600725504\\n```\\n\\nYou can also ask PandasAI to draw a graph:\\n\\n```python\\npandas_ai.run(\\n    df,\\n    \"Plot the histogram of countries showing for each the gpd, using different colors for each bar\",\\n)\\n```\\n\\n![Chart](images/histogram-chart.png?raw=true)' metadata={'source': '/content/pandas-ai/README.md'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_2ZbZ8UKkyZ",
        "outputId": "38c3c1e9-3aec-4f2b-b8eb-bdc8ded07cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='# .env\\n.env\\n\\n# __pycache__\\n__pycache__\\n\\n# macOS\\n.DS_Store\\n\\n# build\\nbuild\\ndist\\npandasai.egg-info\\n\\n#venv\\n/venv', metadata={'source': '/content/pandas-ai/.gitignore'})"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's use Chroma for storing documents.**"
      ],
      "metadata": {
        "id": "jaP-cPZ4H6Ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U chromadb tiktoken"
      ],
      "metadata": {
        "id": "jIZEU3bLIUKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdZxTaXgIEhl",
        "outputId": "fb472f88-7a4f-4350-8716-350e0978f3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "V7Xz5mWZ_ao7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What class should I import from pandasai to instantiate OpenAI llm?\"\n",
        "output = qa.run(query)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovOO6FzyPG4W",
        "outputId": "52a2f18b-820a-4e4f-d390-9d74693c46ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You don't need to import any class from pandasai to instantiate OpenAI llm. Instead, you should import the `OpenAI` class from `pandasai.llm.openai`. Example: `from pandasai.llm.openai import OpenAI`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad, right ? For more detailed info visit the official [LangChain documentation](https://python.langchain.com/en/latest/use_cases/code.html)"
      ],
      "metadata": {
        "id": "jzAzghAsRahQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. [ 🤖 Agents](https://python.langchain.com/en/latest/modules/agents.html)\n",
        "- Agents can be used in variety of tasks and the use case are evolving with the advancement in LLMs.\n",
        "- You could even create your own agent based on Langchain documentation.\n",
        "- Check out my [Auto-GPT with LangChain](https://youtu.be/imDfPmMKEjM) video.\n",
        "- Let's use `ArXiv API Tool`\n",
        "- What is arxiv --> https://arxiv.org/"
      ],
      "metadata": {
        "id": "XKB1UL04RLP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install arxiv"
      ],
      "metadata": {
        "id": "kmGenO-9Y7Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import load_tools, initialize_agent, AgentType\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.0)\n",
        "tools = load_tools(\n",
        "    [\"arxiv\"], \n",
        ")\n",
        "\n",
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "zDJKOy9UZfM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://arxiv.org/abs/1706.03762\n",
        "agent_chain.run(\n",
        "    \"What's the paper 1706.03762 about?\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "4L2ukZh8Zh62",
        "outputId": "adf28058-1e5b-42f1-8bc2-0cadf17a603d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to use a tool to search for the paper on arxiv.org\n",
            "Action: Arxiv\n",
            "Action Input: \"1706.03762\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPublished: 2020-02-12\n",
            "Title: GLU Variants Improve Transformer\n",
            "Authors: Noam Shazeer\n",
            "Summary: Gated Linear Units (arXiv:1612.08083) consist of the component-wise product\n",
            "of two linear projections, one of which is first passed through a sigmoid\n",
            "function. Variations on GLU are possible, using different nonlinear (or even\n",
            "linear) functions in place of sigmoid. We test these variants in the\n",
            "feed-forward sublayers of the Transformer (arXiv:1706.03762)\n",
            "sequence-to-sequence model, and find that some of them yield quality\n",
            "improvements over the typically-used ReLU or GELU activations.\n",
            "\n",
            "Published: 2018-03-16\n",
            "Title: Tensor2Tensor for Neural Machine Translation\n",
            "Authors: Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N. Gomez, Stephan Gouws, Llion Jones, Łukasz Kaiser, Nal Kalchbrenner, Niki Parmar, Ryan Sepassi, Noam Shazeer, Jakob Uszkoreit\n",
            "Summary: Tensor2Tensor is a library for deep learning models that is well-suited for\n",
            "neural machine translation and includes the reference implementation of the\n",
            "state-of-the-art Transformer model.\n",
            "\n",
            "Published: 2022-03-24\n",
            "Title: Transformers Meet Visual Learning Understanding: A Comprehensive Review\n",
            "Authors: Yuting Yang, Licheng Jiao, Xu Liu, Fang Liu, Shuyuan Yang, Zhixi Feng, Xu Tang\n",
            "Summary: Dynamic attention mechanism and global modeling ability make Transformer show\n",
            "strong feature learning ability. In recent years, Transformer has become\n",
            "comparable to CNNs methods in computer vision. This review mainly investigates\n",
            "the current research progress of Transformer in image and video applications,\n",
            "which makes a comprehensive overview of Transformer in visual learning\n",
            "understanding. First, the attention mechanism is reviewed, which plays an\n",
            "essential part in Transformer. And then, the visual Transformer model and the\n",
            "principle of each module are introduced. Thirdly, the existing\n",
            "Transformer-based models are investigated, and their performance is compared in\n",
            "visual learning understanding applications. Three image tasks and two video\n",
            "tasks of computer vision are investigated. The former mainly includes image\n",
            "classification, object detection, and image segmentation. The latter contains\n",
            "object tracking and video classification. It is significant for comparing\n",
            "different models' performance in various tasks on several public benchmark data\n",
            "sets. Finally, ten general problems are summarized, and the developing\n",
            "prospects of the visual Transformer are given in this review.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe paper 1706.03762 is about variations on GLU in the feed-forward sublayers of the Transformer sequence-to-sequence model.\n",
            "Final Answer: The paper 1706.03762 is about variations on GLU in the feed-forward sublayers of the Transformer sequence-to-sequence model.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The paper 1706.03762 is about variations on GLU in the feed-forward sublayers of the Transformer sequence-to-sequence model.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could even use a ArXiv API Wrapper."
      ],
      "metadata": {
        "id": "kGu5EbbpZ3DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities import ArxivAPIWrapper"
      ],
      "metadata": {
        "id": "OBvVnOP3ZxF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv = ArxivAPIWrapper()\n",
        "docs = arxiv.run(\"1706.03762\")\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "UVck_gwFZ8Hc",
        "outputId": "0b0b6976-5b61-48a5-b948-58f113485240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Published: 2023-05-10\\nTitle: RECKONING: Reasoning through Dynamic Knowledge Encoding\\nAuthors: Zeming Chen, Gail Weiss, Eric Mitchell, Asli Celikyilmaz, Antoine Bosselut\\nSummary: Recent studies on transformer-based language models show that they can answer\\nquestions by reasoning over knowledge provided as part of the context (i.e.,\\nin-context reasoning). However, since the available knowledge is often not\\nfiltered for a particular question, in-context reasoning can be sensitive to\\ndistractor facts, additional content that is irrelevant to a question but that\\nmay be relevant for a different question (i.e., not necessarily random noise).\\nIn these situations, the model fails to distinguish the knowledge that is\\nnecessary to answer the question, leading to spurious reasoning and degraded\\nperformance. This reasoning failure contrasts with the model's apparent ability\\nto distinguish its contextual knowledge from all the knowledge it has memorized\\nduring pre-training. Following this observation, we propose teaching the model\\nto reason more robustly by folding the provided contextual knowledge into the\\nmodel's parameters before presenting it with a question. Our method, RECKONING,\\nis a bi-level learning algorithm that teaches language models to reason by\\nupdating their parametric knowledge through back-propagation, allowing them to\\nthen answer questions using the updated parameters. During training, the inner\\nloop rapidly adapts a copy of the model weights to encode contextual knowledge\\ninto its parameters. In the outer loop, the model learns to uses the updated\\nweights to reproduce and answer reasoning questions about the memorized\\nknowledge. Our experiments on two multi-hop reasoning datasets show that\\nRECKONING's performance improves over the in-context reasoning baseline (by up\\nto 4.5%). We also find that compared to in-context reasoning, RECKONING\\ngeneralizes better to longer reasoning chains unseen during training, is more\\nrobust to distractors in the context, and is more computationally efficient\\nwhen multiple questions are asked about the same knowledge.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could even get information about articles from author. Returns 3 articles."
      ],
      "metadata": {
        "id": "YFaDxPXzaIcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = arxiv.run(\"Ashish Vaswani\")\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Br9mmo11aBl8",
        "outputId": "9e0fe678-aec1-47a7-985d-adfb53ce71f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Published: 2016-09-28\\nTitle: Unsupervised Neural Hidden Markov Models\\nAuthors: Ke Tran, Yonatan Bisk, Ashish Vaswani, Daniel Marcu, Kevin Knight\\nSummary: In this work, we present the first results for neuralizing an Unsupervised\\nHidden Markov Model. We evaluate our approach on tag in- duction. Our approach\\noutperforms existing generative models and is competitive with the\\nstate-of-the-art though with a simpler model easily extended to include\\nadditional context.\\n\\nPublished: 2018-04-12\\nTitle: Self-Attention with Relative Position Representations\\nAuthors: Peter Shaw, Jakob Uszkoreit, Ashish Vaswani\\nSummary: Relying entirely on an attention mechanism, the Transformer introduced by\\nVaswani et al. (2017) achieves state-of-the-art results for machine\\ntranslation. In contrast to recurrent and convolutional neural networks, it\\ndoes not explicitly model relative or absolute position information in its\\nstructure. Instead, it requires adding representations of absolute positions to\\nits inputs. In this work we present an alternative approach, extending the\\nself-attention mechanism to efficiently consider representations of the\\nrelative positions, or distances between sequence elements. On the WMT 2014\\nEnglish-to-German and English-to-French translation tasks, this approach yields\\nimprovements of 1.3 BLEU and 0.3 BLEU over absolute position representations,\\nrespectively. Notably, we observe that combining relative and absolute position\\nrepresentations yields no further improvement in translation quality. We\\ndescribe an efficient implementation of our method and cast it as an instance\\nof relation-aware self-attention mechanisms that can generalize to arbitrary\\ngraph-labeled inputs.\\n\\nPublished: 2018-03-16\\nTitle: Tensor2Tensor for Neural Machine Translation\\nAuthors: Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N. Gomez, Stephan Gouws, Llion Jones, Łukasz Kaiser, Nal Kalchbrenner, Niki Parmar, Ryan Sepassi, Noam Shazeer, Jakob Uszkoreit\\nSummary: Tensor2Tensor is a library for deep learning models that is well-suited for\\nneural machine translation and includes the reference implementation of the\\nstate-of-the-art Transformer model.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random input off-course will throw error.\n",
        "docs = arxiv.run(\"1605.08386WWW\")\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l6k20Ui8bSHf",
        "outputId": "f93c32b5-2d54-4779-b582-74a2f49ac891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No good Arxiv Result was found'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Happy Learning 😎**"
      ],
      "metadata": {
        "id": "N6cbNFgLgm22"
      }
    }
  ]
}