{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured\n",
    "- https://unstructured.io/\n",
    "- https://unstructured-io.github.io/unstructured/index.html\n",
    "- https://docs.unstructured.io/api-reference/api-services/python-sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured[all-docs]\n",
      "  Using cached unstructured-0.13.6-py3-none-any.whl (1.9 MB)\n",
      "Collecting unstructured-client\n",
      "  Using cached unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
      "Collecting watermark\n",
      "  Using cached watermark-2.4.3-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Collecting filetype\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-5.2.1-cp311-cp311-macosx_10_9_universal2.whl (8.5 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting emoji\n",
      "  Using cached emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "Collecting dataclasses-json\n",
      "  Using cached dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Collecting python-iso639\n",
      "  Using cached python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.5 MB)\n",
      "Collecting backoff\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting wrapt\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Collecting onnx\n",
      "  Using cached onnx-1.16.0-cp311-cp311-macosx_10_15_universal2.whl (16.5 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Collecting xlrd\n",
      "  Using cached xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Collecting markdown\n",
      "  Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Collecting pypandoc\n",
      "  Using cached pypandoc-1.13-py3-none-any.whl (21 kB)\n",
      "Collecting pillow-heif\n",
      "  Using cached pillow_heif-0.16.0-cp311-cp311-macosx_12_0_arm64.whl (3.3 MB)\n",
      "Collecting unstructured-inference==0.7.29\n",
      "  Using cached unstructured_inference-0.7.29-py3-none-any.whl (59 kB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Collecting google-cloud-vision\n",
      "  Using cached google_cloud_vision-3.7.2-py2.py3-none-any.whl (459 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Collecting pikepdf\n",
      "  Using cached pikepdf-8.15.1-cp311-cp311-macosx_11_0_arm64.whl (4.4 MB)\n",
      "Collecting msg-parser\n",
      "  Using cached msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12\n",
      "  Using cached unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
      "Collecting python-pptx<=0.6.23\n",
      "  Using cached python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
      "Collecting layoutparser[layoutmodels,tesseract]\n",
      "  Using cached layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Collecting opencv-python!=4.7.0.68\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "Collecting onnxruntime>=1.17.0\n",
      "  Using cached onnxruntime-1.17.3-cp311-cp311-macosx_11_0_universal2.whl (14.8 MB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Using cached transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "Collecting certifi>=2023.7.22\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting charset-normalizer>=3.2.0\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Collecting deepdiff>=6.0\n",
      "  Using cached deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "Collecting idna>=3.4\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting jsonpath-python>=1.0.6\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow>=3.19.0\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "Collecting mypy-extensions>=1.0.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting packaging>=23.1\n",
      "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting six>=1.16.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting typing-inspect>=0.9.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting urllib3>=1.26.18\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Collecting ipython>=6.0\n",
      "  Using cached ipython-8.24.0-py3-none-any.whl (816 kB)\n",
      "Collecting importlib-metadata>=1.4\n",
      "  Using cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: setuptools in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from watermark) (65.5.0)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting decorator\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jedi>=0.16\n",
      "  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting matplotlib-inline\n",
      "  Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41\n",
      "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "Collecting pygments>=2.4.0\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "Collecting stack-data\n",
      "  Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting traitlets>=5.13.0\n",
      "  Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "Collecting pexpect>4.3\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "Collecting Pillow>=3.3.2\n",
      "  Using cached pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Using cached XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1\n",
      "  Using cached google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Using cached proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Collecting olefile>=0.46\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2024.4.28-cp311-cp311-macosx_11_0_arm64.whl (278 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "Collecting Deprecated\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (176 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Using cached grpcio-1.63.0-cp311-cp311-macosx_10_9_universal2.whl (10.1 MB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl (14 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3\n",
      "  Using cached parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl (410 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Collecting iopath\n",
      "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.3.0-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "Collecting effdet\n",
      "  Using cached effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting pure-eval\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Using cached grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting timm>=0.9.2\n",
      "  Using cached timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Using cached pycocotools-2.0.7-cp311-cp311-macosx_10_9_universal2.whl (170 kB)\n",
      "Collecting omegaconf>=2.0\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Using cached pypdfium2-4.29.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib>=2.1.0\n",
      "  Using cached matplotlib-3.8.4-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (245 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.51.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: wcwidth, pytz, pure-eval, ptyprocess, mpmath, flatbuffers, filetype, antlr4-python3-runtime, zipp, XlsxWriter, xlrd, wrapt, urllib3, tzdata, typing-extensions, traitlets, tqdm, tabulate, sympy, soupsieve, six, safetensors, regex, rapidfuzz, pyyaml, python-multipart, python-magic, python-iso639, pypdfium2, pypdf, pyparsing, pypandoc, pygments, pycparser, pyasn1, protobuf, prompt-toolkit, portalocker, Pillow, pexpect, parso, packaging, ordered-set, olefile, numpy, networkx, mypy-extensions, MarkupSafe, markdown, lxml, kiwisolver, jsonpath-python, joblib, idna, humanfriendly, grpcio, fsspec, fonttools, filelock, executing, et-xmlfile, emoji, decorator, cycler, click, charset-normalizer, chardet, certifi, cachetools, backoff, unstructured.pytesseract, typing-inspect, scipy, rsa, requests, python-pptx, python-docx, python-dateutil, pytesseract, pyasn1-modules, proto-plus, pillow-heif, pdf2image, openpyxl, opencv-python, onnx, omegaconf, nltk, msg-parser, matplotlib-inline, marshmallow, langdetect, jinja2, jedi, iopath, importlib-metadata, googleapis-common-protos, Deprecated, deepdiff, contourpy, coloredlogs, cffi, beautifulsoup4, asttokens, torch, stack-data, pikepdf, pandas, onnxruntime, matplotlib, huggingface-hub, grpcio-status, google-auth, dataclasses-json, cryptography, unstructured-client, torchvision, tokenizers, pycocotools, pdfminer.six, ipython, google-api-core, watermark, unstructured, transformers, timm, pdfplumber, layoutparser, google-cloud-vision, effdet, unstructured-inference\n",
      "\u001b[33m  DEPRECATION: antlr4-python3-runtime is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: langdetect is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for langdetect ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: iopath is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for iopath ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Deprecated-1.2.14 MarkupSafe-2.1.5 Pillow-10.3.0 XlsxWriter-3.2.0 antlr4-python3-runtime-4.9.3 asttokens-2.4.1 backoff-2.2.1 beautifulsoup4-4.12.3 cachetools-5.3.3 certifi-2024.2.2 cffi-1.16.0 chardet-5.2.0 charset-normalizer-3.3.2 click-8.1.7 coloredlogs-15.0.1 contourpy-1.2.1 cryptography-42.0.5 cycler-0.12.1 dataclasses-json-0.6.5 decorator-5.1.1 deepdiff-7.0.1 effdet-0.4.1 emoji-2.11.1 et-xmlfile-1.1.0 executing-2.0.1 filelock-3.14.0 filetype-1.2.0 flatbuffers-24.3.25 fonttools-4.51.0 fsspec-2024.3.1 google-api-core-2.19.0 google-auth-2.29.0 google-cloud-vision-3.7.2 googleapis-common-protos-1.63.0 grpcio-1.63.0 grpcio-status-1.62.2 huggingface-hub-0.23.0 humanfriendly-10.0 idna-3.7 importlib-metadata-7.1.0 iopath-0.1.10 ipython-8.24.0 jedi-0.19.1 jinja2-3.1.3 joblib-1.4.2 jsonpath-python-1.0.6 kiwisolver-1.4.5 langdetect-1.0.9 layoutparser-0.3.4 lxml-5.2.1 markdown-3.6 marshmallow-3.21.2 matplotlib-3.8.4 matplotlib-inline-0.1.7 mpmath-1.3.0 msg-parser-1.2.0 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 olefile-0.47 omegaconf-2.3.0 onnx-1.16.0 onnxruntime-1.17.3 opencv-python-4.9.0.80 openpyxl-3.1.2 ordered-set-4.1.0 packaging-24.0 pandas-2.2.2 parso-0.8.4 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.0 pexpect-4.9.0 pikepdf-8.15.1 pillow-heif-0.16.0 portalocker-2.8.2 prompt-toolkit-3.0.43 proto-plus-1.23.0 protobuf-4.25.3 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycocotools-2.0.7 pycparser-2.22 pygments-2.17.2 pypandoc-1.13 pyparsing-3.1.2 pypdf-4.2.0 pypdfium2-4.29.0 pytesseract-0.3.10 python-dateutil-2.9.0.post0 python-docx-1.1.2 python-iso639-2024.4.27 python-magic-0.4.27 python-multipart-0.0.9 python-pptx-0.6.23 pytz-2024.1 pyyaml-6.0.1 rapidfuzz-3.9.0 regex-2024.4.28 requests-2.31.0 rsa-4.9 safetensors-0.4.3 scipy-1.13.0 six-1.16.0 soupsieve-2.5 stack-data-0.6.3 sympy-1.12 tabulate-0.9.0 timm-0.9.16 tokenizers-0.19.1 torch-2.3.0 torchvision-0.18.0 tqdm-4.66.4 traitlets-5.14.3 transformers-4.40.1 typing-extensions-4.11.0 typing-inspect-0.9.0 tzdata-2024.1 unstructured-0.13.6 unstructured-client-0.22.0 unstructured-inference-0.7.29 unstructured.pytesseract-0.3.12 urllib3-2.2.1 watermark-2.4.3 wcwidth-0.2.13 wrapt-1.16.0 xlrd-2.0.1 zipp-3.18.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"unstructured[all-docs]\" unstructured-client watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "import json\n",
    "\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unstructured       : 0.13.6\n",
      "unstructured_client: 0.22.0\n",
      "json               : 2.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package unstructured.partition in unstructured:\n",
      "\n",
      "NAME\n",
      "    unstructured.partition\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    auto\n",
      "    common\n",
      "    csv\n",
      "    doc\n",
      "    docx\n",
      "    email\n",
      "    epub\n",
      "    html\n",
      "    image\n",
      "    json\n",
      "    lang\n",
      "    md\n",
      "    model_init\n",
      "    msg\n",
      "    odt\n",
      "    org\n",
      "    pdf\n",
      "    pdf_image (package)\n",
      "    ppt\n",
      "    pptx\n",
      "    rst\n",
      "    rtf\n",
      "    strategies\n",
      "    text\n",
      "    text_type\n",
      "    tsv\n",
      "    utils (package)\n",
      "    xlsx\n",
      "    xml\n",
      "\n",
      "FILE\n",
      "    /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages/unstructured/partition/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unstructured.partition\n",
    "\n",
    "help(unstructured.partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"data/gpt4all.pdf\"\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "elements = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Text at 0x386b8f590>,\n",
       " <unstructured.documents.elements.Title at 0x386eaf790>,\n",
       " <unstructured.documents.elements.Title at 0x35ad93510>,\n",
       " <unstructured.documents.elements.Text at 0x386aeaf50>,\n",
       " <unstructured.documents.elements.Title at 0x386f0d950>,\n",
       " <unstructured.documents.elements.Title at 0x386f0f310>,\n",
       " <unstructured.documents.elements.Title at 0x386ed3b90>,\n",
       " <unstructured.documents.elements.Title at 0x386f0e5d0>,\n",
       " <unstructured.documents.elements.Title at 0x386cc4690>,\n",
       " <unstructured.documents.elements.Title at 0x386b8e390>,\n",
       " <unstructured.documents.elements.Title at 0x386f0f4d0>,\n",
       " <unstructured.documents.elements.Title at 0x386ed23d0>,\n",
       " <unstructured.documents.elements.Title at 0x387008690>,\n",
       " <unstructured.documents.elements.Title at 0x386ed0490>,\n",
       " <unstructured.documents.elements.Title at 0x387008910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed0f50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed3810>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed2510>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed0a50>,\n",
       " <unstructured.documents.elements.Title at 0x386ed1710>,\n",
       " <unstructured.documents.elements.Title at 0x176961510>,\n",
       " <unstructured.documents.elements.Text at 0x1769a1510>,\n",
       " <unstructured.documents.elements.Title at 0x386c1a250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed3710>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35a973f10>,\n",
       " <unstructured.documents.elements.Title at 0x38700aa50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed2010>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386c2d7d0>,\n",
       " <unstructured.documents.elements.Title at 0x34e919510>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386c2c910>,\n",
       " <unstructured.documents.elements.Title at 0x386c19450>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386e29890>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed1690>,\n",
       " <unstructured.documents.elements.Title at 0x386e2a850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed0350>,\n",
       " <unstructured.documents.elements.Title at 0x35ad90350>,\n",
       " <unstructured.documents.elements.Title at 0x386d87450>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386d84c10>,\n",
       " <unstructured.documents.elements.Title at 0x386ed10d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed2850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ed3850>,\n",
       " <unstructured.documents.elements.Title at 0x1768e9510>,\n",
       " <unstructured.documents.elements.Title at 0x386c1bdd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386b8eb90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386b8c250>,\n",
       " <unstructured.documents.elements.Title at 0x35ad64390>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x34da5d990>,\n",
       " <unstructured.documents.elements.Text at 0x386b1bed0>,\n",
       " <unstructured.documents.elements.Text at 0x35ae62c10>,\n",
       " <unstructured.documents.elements.Text at 0x35ad9a790>,\n",
       " <unstructured.documents.elements.Text at 0x3870a7290>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386cc7a50>,\n",
       " <unstructured.documents.elements.Title at 0x386d3f990>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176c74f90>,\n",
       " <unstructured.documents.elements.Text at 0x176c841d0>,\n",
       " <unstructured.documents.elements.Text at 0x386b1a550>,\n",
       " <unstructured.documents.elements.Text at 0x386d3fe10>,\n",
       " <unstructured.documents.elements.Text at 0x386ced850>,\n",
       " <unstructured.documents.elements.Text at 0x35ea703d0>,\n",
       " <unstructured.documents.elements.Text at 0x387028290>,\n",
       " <unstructured.documents.elements.Text at 0x387029d10>,\n",
       " <unstructured.documents.elements.Text at 0x386b19a50>,\n",
       " <unstructured.documents.elements.Title at 0x386f0e590>,\n",
       " <unstructured.documents.elements.Text at 0x3870a7a10>,\n",
       " <unstructured.documents.elements.Text at 0x386f0d110>,\n",
       " <unstructured.documents.elements.Text at 0x386f0ec90>,\n",
       " <unstructured.documents.elements.Text at 0x176c76390>,\n",
       " <unstructured.documents.elements.Text at 0x35aa11d50>,\n",
       " <unstructured.documents.elements.Text at 0x176950bd0>,\n",
       " <unstructured.documents.elements.Text at 0x176c857d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x38700f6d0>,\n",
       " <unstructured.documents.elements.Text at 0x38700d050>,\n",
       " <unstructured.documents.elements.Text at 0x386f70cd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3870ece10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3870eddd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386d16fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386e7dd50>,\n",
       " <unstructured.documents.elements.Title at 0x3870ee290>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386e7dd90>,\n",
       " <unstructured.documents.elements.Title at 0x386d14e10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x387018750>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x387042090>,\n",
       " <unstructured.documents.elements.Title at 0x386cda890>,\n",
       " <unstructured.documents.elements.Title at 0x176d50f50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176d52b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386ddacd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386e015d0>,\n",
       " <unstructured.documents.elements.Title at 0x35a8dad10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176da1d50>,\n",
       " <unstructured.documents.elements.Title at 0x386c06c50>,\n",
       " <unstructured.documents.elements.Title at 0x176955e50>,\n",
       " <unstructured.documents.elements.Title at 0x35ac9b310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176961f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176e721d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176ce8c90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176ce9550>,\n",
       " <unstructured.documents.elements.Title at 0x176ce9c50>,\n",
       " <unstructured.documents.elements.Title at 0x176ce9990>,\n",
       " <unstructured.documents.elements.Title at 0x176cea3d0>,\n",
       " <unstructured.documents.elements.Title at 0x3355dac50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35ad8ae50>,\n",
       " <unstructured.documents.elements.Title at 0x176ceb550>,\n",
       " <unstructured.documents.elements.Title at 0x176ceb9d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176c84210>,\n",
       " <unstructured.documents.elements.Title at 0x176cebc90>,\n",
       " <unstructured.documents.elements.Text at 0x176c99890>,\n",
       " <unstructured.documents.elements.Title at 0x386ca7490>,\n",
       " <unstructured.documents.elements.Title at 0x176c9a490>,\n",
       " <unstructured.documents.elements.Title at 0x176c994d0>,\n",
       " <unstructured.documents.elements.Text at 0x176c9a410>,\n",
       " <unstructured.documents.elements.Title at 0x176c9aa10>,\n",
       " <unstructured.documents.elements.Title at 0x176c852d0>,\n",
       " <unstructured.documents.elements.Title at 0x176e42f90>,\n",
       " <unstructured.documents.elements.Title at 0x386c05bd0>,\n",
       " <unstructured.documents.elements.Title at 0x35ac9bf90>,\n",
       " <unstructured.documents.elements.Title at 0x176c863d0>,\n",
       " <unstructured.documents.elements.Text at 0x176c87d90>,\n",
       " <unstructured.documents.elements.Title at 0x333180850>,\n",
       " <unstructured.documents.elements.Title at 0x176c85e50>,\n",
       " <unstructured.documents.elements.Title at 0x386b22610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x336521250>,\n",
       " <unstructured.documents.elements.Title at 0x386e7c850>,\n",
       " <unstructured.documents.elements.Title at 0x35a9c0350>,\n",
       " <unstructured.documents.elements.Title at 0x33656db90>,\n",
       " <unstructured.documents.elements.Title at 0x176c991d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176e718d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386b59a90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x340a1c710>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35aaba010>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386b42b10>,\n",
       " <unstructured.documents.elements.Title at 0x386d15a90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386c05710>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x386b437d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176e73f90>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b0c5cfcf93a217591e27d5c97845f59b\",\n",
      "    \"text\": \"3 2 0 2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            263.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            303.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            303.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            263.81000000000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d71e9973e25dde0d96dc422b5a8fd429\",\n",
      "    \"text\": \"v o N 6\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            308.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            358.25\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            358.25\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            308.81000000000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"da9a4b336f710784f847aa01becae2d8\",\n",
      "    \"text\": \"] L C . s c [\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            368.24999999999994\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            428.78999999999996\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            428.78999999999996\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            368.24999999999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"cf466a5a422c76d228e6f9c56a8428ce\",\n",
      "    \"text\": \"1 v 1 3 9 4 0 . 1 1 3 2 : v i X r a\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            438.78999999999996\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            604.89\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            604.89\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            438.78999999999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"da9a4b336f710784f847aa01becae2d8\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"741c25a4fb94e81aa7239a1c0534a9e8\",\n",
      "    \"text\": \"GPT4All: An Ecosystem of Open Source Compressed Language Models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            77.497,\n",
      "            78.40315579999992\n",
      "          ],\n",
      "          [\n",
      "            77.497,\n",
      "            92.74935579999999\n",
      "          ],\n",
      "          [\n",
      "            517.7818779999999,\n",
      "            92.74935579999999\n",
      "          ],\n",
      "          [\n",
      "            517.7818779999999,\n",
      "            78.40315579999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3f394fcdfd3c020fa260d031c7aa3551\",\n",
      "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            69.06,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            69.06,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            170.67834999999997,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            170.67834999999997,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c9f10a02ba1baf5861871dea2427ea13\",\n",
      "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.531,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            196.531,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            279.2363818,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            279.2363818,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"1fb7ac4ca22ad79ab5acc099895231b9\",\n",
      "    \"text\": \"Adam Treat Nomic AI adam@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.538,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            318.538,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            396.24615,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            396.24615,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c3528c06b42170925c8845cd0516afaf\",\n",
      "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            435.058,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            435.058,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            518.7436999999999,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            518.7436999999999,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"87aa6b53bb4ad01ca3786c2082164fa2\",\n",
      "    \"text\": \"Richard Guo Nomic AI richard@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            100.43099999999997,\n",
      "            173.28351589999988\n",
      "          ],\n",
      "          [\n",
      "            100.43099999999997,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            196.07179999999994,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            196.07179999999994,\n",
      "            173.28351589999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0f9ab7485cd89cf606234ade290a822f\",\n",
      "    \"text\": \"Ben Schmidt Nomic AI ben@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            261.77199999999993,\n",
      "            173.28351589999988\n",
      "          ],\n",
      "          [\n",
      "            261.77199999999993,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            333.5026,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            333.5026,\n",
      "            173.28351589999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9eace5e83f6c7f55784da14b30801a6e\",\n",
      "    \"text\": \"GPT4All Community Planet Earth\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            392.05999999999995,\n",
      "            173.28351589999988\n",
      "          ],\n",
      "          [\n",
      "            392.05999999999995,\n",
      "            199.54930159999992\n",
      "          ],\n",
      "          [\n",
      "            501.98714449999994,\n",
      "            199.54930159999992\n",
      "          ],\n",
      "          [\n",
      "            501.98714449999994,\n",
      "            173.28351589999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"adefd49403515997446e8633e38d94f7\",\n",
      "    \"text\": \"Brandon Duderstadt\\u2217 Nomic AI brandon@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            145.07499999999993,\n",
      "            235.17709939999986\n",
      "          ],\n",
      "          [\n",
      "            145.07499999999993,\n",
      "            276.4731873999999\n",
      "          ],\n",
      "          [\n",
      "            255.25451412999993,\n",
      "            276.4731873999999\n",
      "          ],\n",
      "          [\n",
      "            255.25451412999993,\n",
      "            235.17709939999986\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"Hfootnote.1\",\n",
      "          \"start_index\": 42\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"aa800040abcb3a68245ea9e047eb25a1\",\n",
      "    \"text\": \"Andriy Mulyar\\u2217 Nomic AI andriy@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            352.39699999999993,\n",
      "            235.17709939999997\n",
      "          ],\n",
      "          [\n",
      "            352.39699999999993,\n",
      "            276.47318740000003\n",
      "          ],\n",
      "          [\n",
      "            442.06024999999994,\n",
      "            276.47318740000003\n",
      "          ],\n",
      "          [\n",
      "            442.06024999999994,\n",
      "            235.17709939999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "    \"text\": \"Abstract\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            157.75799999999992,\n",
      "            304.80951590000006\n",
      "          ],\n",
      "          [\n",
      "            157.75799999999992,\n",
      "            316.7646159000001\n",
      "          ],\n",
      "          [\n",
      "            202.24292709999992,\n",
      "            316.7646159000001\n",
      "          ],\n",
      "          [\n",
      "            202.24292709999992,\n",
      "            304.80951590000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a90d3e5cedb83aa21ccdb130e575542b\",\n",
      "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            87.625,\n",
      "            331.47432159999994\n",
      "          ],\n",
      "          [\n",
      "            87.625,\n",
      "            437.07792159999997\n",
      "          ],\n",
      "          [\n",
      "            273.7749204880001,\n",
      "            437.07792159999997\n",
      "          ],\n",
      "          [\n",
      "            273.7749204880001,\n",
      "            331.47432159999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3f27ae624f926eb91c661791f642f9e3\",\n",
      "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4All model family, as well as the evolution of the GPT4All project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            87.874,\n",
      "            444.3423216\n",
      "          ],\n",
      "          [\n",
      "            87.874,\n",
      "            573.8569216\n",
      "          ],\n",
      "          [\n",
      "            272.1287004640001,\n",
      "            573.8569216\n",
      "          ],\n",
      "          [\n",
      "            272.1287004640001,\n",
      "            444.3423216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"185bfce5f50e0f150589bc1d066df5a9\",\n",
      "    \"text\": \"variety of queries, responding only with the now infa- mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than a week prior to the release of GPT-4 (Verge, 2023). GPT4All started as one of these variants.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.813,\n",
      "            306.45532159999993\n",
      "          ],\n",
      "          [\n",
      "            305.813,\n",
      "            424.01392159999995\n",
      "          ],\n",
      "          [\n",
      "            526.1474706388001,\n",
      "            424.01392159999995\n",
      "          ],\n",
      "          [\n",
      "            526.1474706388001,\n",
      "            306.45532159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Vincent\",\n",
      "          \"url\": \"cite.verge2023ai\",\n",
      "          \"start_index\": 106\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.verge2023ai\",\n",
      "          \"start_index\": 115\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Touvronetal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 345\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 361\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"McMil\",\n",
      "          \"url\": \"cite.wsj_llama\",\n",
      "          \"start_index\": 367\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"lan\",\n",
      "          \"url\": \"cite.wsj_llama\",\n",
      "          \"start_index\": 374\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.wsj_llama\",\n",
      "          \"start_index\": 379\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Verge\",\n",
      "          \"url\": \"cite.verge-meta-ai-leak-2023\",\n",
      "          \"start_index\": 474\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.verge-meta-ai-leak-2023\",\n",
      "          \"start_index\": 481\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c4a4c71ac956e6c69d6d761d32e81e0f\",\n",
      "    \"text\": \"In this paper, we tell the story of GPT4All. We com- ment on the technical details of the original GPT4All model (Anand et al., 2023), as well as the evolution of GPT4All from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.783,\n",
      "            426.5143216\n",
      "          ],\n",
      "          [\n",
      "            305.783,\n",
      "            544.0729216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            544.0729216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            426.5143216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Anandetal .,\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 114\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 128\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"4c756886e4dbf688c1568c8e65bda77d\",\n",
      "    \"text\": \"2 The Original GPT4All Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            557.3085159\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            569.2636159\n",
      "          ],\n",
      "          [\n",
      "            474.5295835,\n",
      "            569.2636159\n",
      "          ],\n",
      "          [\n",
      "            474.5295835,\n",
      "            557.3085159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"49fcd165ead3de8d30afc73d0ac33943\",\n",
      "    \"text\": \"2.1 Data Collection and Curation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            578.7575833999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            588.7201834\n",
      "          ],\n",
      "          [\n",
      "            454.4751514,\n",
      "            588.7201834\n",
      "          ],\n",
      "          [\n",
      "            454.4751514,\n",
      "            578.7575833999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b06f3763a242682a426d25678eee97da\",\n",
      "    \"text\": \"1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            589.5385159\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            76.84355,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            76.84355,\n",
      "            589.5385159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"49fcd165ead3de8d30afc73d0ac33943\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
      "    \"text\": \"Introduction\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            88.79865,\n",
      "            589.5385159\n",
      "          ],\n",
      "          [\n",
      "            88.79865,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            153.6789777,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            153.6789777,\n",
      "            589.5385159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3abe933a09cfef67aa4b1b9a3a889472\",\n",
      "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a variety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAI, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model. Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.507,\n",
      "            611.3753216\n",
      "          ],\n",
      "          [\n",
      "            70.507,\n",
      "            752.8449216\n",
      "          ],\n",
      "          [\n",
      "            290.7879641256002,\n",
      "            752.8449216\n",
      "          ],\n",
      "          [\n",
      "            290.7879641256002,\n",
      "            611.3753216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"OpenAI\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 232\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 240\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"BBCNews\",\n",
      "          \"url\": \"cite.bbc2023chatgpt\",\n",
      "          \"start_index\": 578\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b11f30bd83a1069848654cfbd663d188\",\n",
      "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3.5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023. In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4All, we focused substantial effort on dataset curation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.833,\n",
      "            595.3333216\n",
      "          ],\n",
      "          [\n",
      "            305.833,\n",
      "            736.8029216\n",
      "          ],\n",
      "          [\n",
      "            526.0666639902,\n",
      "            736.8029216\n",
      "          ],\n",
      "          [\n",
      "            526.0666639902,\n",
      "            595.3333216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Sanhetal .,\",\n",
      "          \"url\": \"cite.sanh2021multitask\",\n",
      "          \"start_index\": 395\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.sanh2021multitask\",\n",
      "          \"start_index\": 408\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Taorietal\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 460\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 474\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
      "    \"text\": \"\\u2217 Shared Senior Authorship\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            763.3930544\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            177.0362924,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            177.0362924,\n",
      "            763.3930544\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4ab72a88d0df5f2cb17bd34cb4904132\",\n",
      "    \"text\": \"The collected dataset was loaded into Atlas (AI, 2023)\\u2014a visual interface for exploring and tagging mas- sive unstructured datasets \\u2014for data curation. Using At-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            739.3033216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0614137000001,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0614137000001,\n",
      "            739.3033216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"AI\",\n",
      "          \"url\": \"cite.atlas-nomic-ai\",\n",
      "          \"start_index\": 45\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.atlas-nomic-ai\",\n",
      "          \"start_index\": 49\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3a30a05cb24cdd567f6da500d522c05f\",\n",
      "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            167.6629216\n",
      "          ],\n",
      "          [\n",
      "            290.7879242752001,\n",
      "            167.6629216\n",
      "          ],\n",
      "          [\n",
      "            290.7879242752001,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"605prompt - responsepairs , inFigure1a\",\n",
      "          \"url\": \"figure.caption.1\",\n",
      "          \"start_index\": 337\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b7e78c182dbf1ff32cc960ed1022019c\",\n",
      "    \"text\": \"2.2 Model Training\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            178.24758339999994\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            188.2101833999999\n",
      "          ],\n",
      "          [\n",
      "            159.80213020000002,\n",
      "            188.2101833999999\n",
      "          ],\n",
      "          [\n",
      "            159.80213020000002,\n",
      "            178.24758339999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1e9fb4a4895681f2277acac805311c72\",\n",
      "    \"text\": \"The original GPT4All model was a fine tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository1.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.557,\n",
      "            194.20532159999993\n",
      "          ],\n",
      "          [\n",
      "            70.557,\n",
      "            275.8989216\n",
      "          ],\n",
      "          [\n",
      "            289.13843652000014,\n",
      "            275.8989216\n",
      "          ],\n",
      "          [\n",
      "            289.13843652000014,\n",
      "            194.20532159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Huetal .,\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 176\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 187\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"repository1\",\n",
      "          \"url\": \"Hfootnote.2\",\n",
      "          \"start_index\": 318\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"b7e78c182dbf1ff32cc960ed1022019c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
      "    \"text\": \"2.3 Model Access\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            286.48358339999993\n",
      "          ],\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            296.4461833999999\n",
      "          ],\n",
      "          [\n",
      "            151.10478040000004,\n",
      "            296.4461833999999\n",
      "          ],\n",
      "          [\n",
      "            151.10478040000004,\n",
      "            286.48358339999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2fd8d8cedd78e9080e5e641d58d85f58\",\n",
      "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.398,\n",
      "            302.4413215999999\n",
      "          ],\n",
      "          [\n",
      "            70.398,\n",
      "            360.2239216\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            360.2239216\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            302.4413215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8dfde8cadfe9b32242bf92a46677da95\",\n",
      "    \"text\": \"Our research and development costs were dominated by \\u223c$800 in GPU spend (rented from Lambda Labs and Paperspace) and \\u223c$500 in OpenAI API spend. Our final GPT4All model could be trained in about eight hours on a Lambda Labs DGX A100 8x 80GB for a total cost of \\u223c$100.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            362.3993216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            432.1369216\n",
      "          ],\n",
      "          [\n",
      "            289.1357349720001,\n",
      "            432.1369216\n",
      "          ],\n",
      "          [\n",
      "            289.1357349720001,\n",
      "            362.3993216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d6d4ad115eb010fa18f8db60b6e16130\",\n",
      "    \"text\": \"2.4 Model Evaluation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            442.72158340000004\n",
      "          ],\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            452.68418340000005\n",
      "          ],\n",
      "          [\n",
      "            169.29648800000004,\n",
      "            452.68418340000005\n",
      "          ],\n",
      "          [\n",
      "            169.29648800000004,\n",
      "            442.72158340000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f62efce43d06b955f6a5dcddf65af02c\",\n",
      "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100. We found that GPT4All produces stochastically lower ground truth perplexities than alpaca-lora (Anand et al., 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.398,\n",
      "            458.6793216\n",
      "          ],\n",
      "          [\n",
      "            70.398,\n",
      "            588.1939216\n",
      "          ],\n",
      "          [\n",
      "            290.78419826280003,\n",
      "            588.1939216\n",
      "          ],\n",
      "          [\n",
      "            290.78419826280003,\n",
      "            458.6793216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Wangetal .,\",\n",
      "          \"url\": \"cite.wang2023selfinstruct\",\n",
      "          \"start_index\": 113\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.wang2023selfinstruct\",\n",
      "          \"start_index\": 126\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"(\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 542\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"etal .,\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 549\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 557\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"d6d4ad115eb010fa18f8db60b6e16130\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"12c1dd0555bedb5ccc2a4d6366af96c7\",\n",
      "    \"text\": \"3 From a Model to an Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            600.3705159\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            612.3256159\n",
      "          ],\n",
      "          [\n",
      "            246.96462300000002,\n",
      "            612.3256159\n",
      "          ],\n",
      "          [\n",
      "            246.96462300000002,\n",
      "            600.3705159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0dffdafdd5dd329002b2c54c4cb1110b\",\n",
      "    \"text\": \"3.1 GPT4All-J: Repository Growth and the implications of the LLaMA License\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            621.0545834\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            642.9721834\n",
      "          ],\n",
      "          [\n",
      "            261.8091916,\n",
      "            642.9721834\n",
      "          ],\n",
      "          [\n",
      "            261.8091916,\n",
      "            621.0545834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"eefe269a0febf2b64874bf58517dfd42\",\n",
      "    \"text\": \"The GPT4All repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants. As the Nomic discord, the home of online discussion about GPT4All, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.557,\n",
      "            648.9673216\n",
      "          ],\n",
      "          [\n",
      "            70.557,\n",
      "            754.5709216\n",
      "          ],\n",
      "          [\n",
      "            290.3781824640001,\n",
      "            754.5709216\n",
      "          ],\n",
      "          [\n",
      "            290.3781824640001,\n",
      "            648.9673216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"figure.caption.3\",\n",
      "          \"start_index\": 125\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0dffdafdd5dd329002b2c54c4cb1110b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
      "    \"text\": \"1https://github.com/nomic-ai/gpt4all\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            82.406,\n",
      "            763.6547055999999\n",
      "          ],\n",
      "          [\n",
      "            82.406,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            203.33735880000003,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            203.33735880000003,\n",
      "            763.6547055999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0d8886d9a22209bc8437feee3638a5ca\",\n",
      "    \"text\": \"The LLaMA model that GPT4All was based on was licensed for research only, which severely limited the set of domains that GPT4All could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4All model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4All-J also had an augmented training set, which contained multi-turn QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            239.3939216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            239.3939216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"WangandKomatsuzaki\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 335\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 357\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"92e00ff1cb81d6b459be0fe6dc472d52\",\n",
      "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4All-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            242.06532159999995\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            347.6689216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            347.6689216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            242.06532159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Conoveretal .,\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 205\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 221\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"73c58b69befd3e9f585d675406001042\",\n",
      "    \"text\": \"3.2 GPT4All-Snoozy: the Emergence of the\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            359.8695834\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            369.8321834\n",
      "          ],\n",
      "          [\n",
      "            496.7365006000001,\n",
      "            369.8321834\n",
      "          ],\n",
      "          [\n",
      "            496.7365006000001,\n",
      "            359.8695834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
      "    \"text\": \"GPT4All Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            328.558,\n",
      "            371.8245834\n",
      "          ],\n",
      "          [\n",
      "            328.558,\n",
      "            381.7871834\n",
      "          ],\n",
      "          [\n",
      "            414.0669958,\n",
      "            381.7871834\n",
      "          ],\n",
      "          [\n",
      "            414.0669958,\n",
      "            371.8245834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"024462343235bc2daac9cce9bb6c634e\",\n",
      "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base model due to its superior base metrics when compared to GPT-J. Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s training data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4All-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.395,\n",
      "            388.7263216\n",
      "          ],\n",
      "          [\n",
      "            305.395,\n",
      "            542.1499216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            542.1499216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            388.7263216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"59eced6045d5b1cdba3ade16138ac760\",\n",
      "    \"text\": \"Concurrently with the development of GPT4All, sev- eral organizations such as LMSys, Stability AI, BAIR, and Databricks built and deployed open source language models. We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increas- ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            544.8223216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            722.1569216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            722.1569216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            544.8223216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "    \"text\": \"3.3 The Current State of GPT4All\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            734.3565834\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            744.3191833999999\n",
      "          ],\n",
      "          [\n",
      "            457.8823606,\n",
      "            744.3191833999999\n",
      "          ],\n",
      "          [\n",
      "            457.8823606,\n",
      "            734.3565834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb61f57fcce8e8a2646dc76a8c093748\",\n",
      "    \"text\": \"Today, GPT4All is focused on improving the accessi- bility of open source language models. The repository\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.833,\n",
      "            751.2583216\n",
      "          ],\n",
      "          [\n",
      "            305.833,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0606565440002,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0606565440002,\n",
      "            751.2583216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"41e0446a073aef5a69d9255c3c4e97d3\",\n",
      "    \"text\": \"(a)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            120.238,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            120.238,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            130.32900999999998,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            130.32900999999998,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"58733fcd98d72185ade05bca0dfb629e\",\n",
      "    \"text\": \"(b)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            226.15,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            226.15,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            236.750106,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            236.750106,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c46d4a1f11826347b7e9e26d86ba9cf0\",\n",
      "    \"text\": \"(c)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            338.03,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            338.03,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            348.12101,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            348.12101,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9698a5149dc8973c56d946c401011e29\",\n",
      "    \"text\": \"(d)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            454.856,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            454.856,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            465.45610600000003,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            465.45610600000003,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2e03616f70996bcde479197f45b4857c\",\n",
      "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4All train set. Panel (a) shows the original uncurated data. The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4All data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4All-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.507,\n",
      "            203.06932159999997\n",
      "          ],\n",
      "          [\n",
      "            70.507,\n",
      "            296.71892160000004\n",
      "          ],\n",
      "          [\n",
      "            525.6591306453995,\n",
      "            296.71892160000004\n",
      "          ],\n",
      "          [\n",
      "            525.6591306453995,\n",
      "            203.06932159999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            76.844,\n",
      "            313.32293119999997\n",
      "          ],\n",
      "          [\n",
      "            76.844,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            98.9544702,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            98.9544702,\n",
      "            313.32293119999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"887a46a4686a15ffec4a85995e852a77\",\n",
      "    \"text\": \"BoolQ PIQA HellaSwag WinoG. ARC-e ARC-c OBQA Avg.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            245.318839,\n",
      "            313.32293119999997\n",
      "          ],\n",
      "          [\n",
      "            245.318839,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            523.1689492000004,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            523.1689492000004,\n",
      "            313.32293119999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"52cfb840240d199decfe24db5e27ce5d\",\n",
      "    \"text\": \"GPT4All-J 6B v1.0* GPT4All-J v1.1-breezy* GPT4All-J v1.2-jazzy* GPT4All-J v1.3-groovy* GPT4All-J Lora 6B* GPT4All LLaMa Lora 7B* GPT4All 13B snoozy* GPT4All Falcon Nous-Hermes (Nous-Research, 2023b) Nous-Hermes2 (Nous-Research, 2023c) Nous-Puffin (Nous-Research, 2023d) Dolly 6B* (Conover et al., 2023a) Dolly 12B* (Conover et al., 2023b) Alpaca 7B* (Taori et al., 2023) Alpaca Lora 7B* (Wang, 2023) GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B* (Touvron et al., 2023) LLama 13B* (Touvron et al., 2023) Pythia 6.7B* (Biderman et al., 2023) Pythia 12B* (Biderman et al., 2023) Fastchat T5* (Zheng et al., 2023) Fastchat Vicu\\u00f1a* 7B (Zheng et al., 2023) Fastchat Vicu\\u00f1a 13B* (Zheng et al., 2023) StableVicu\\u00f1a RLHF* (Stability-AI, 2023) StableLM Tuned* (Stability-AI, 2023) StableLM Base* (Stability-AI, 2023) Koala 13B* (Geng et al., 2023) Open Assistant Pythia 12B* Mosaic MPT7B (MosaicML-Team, 2023) Mosaic mpt-instruct (MosaicML-Team, 2023) Mosaic mpt-chat (MosaicML-Team, 2023) Wizard 7B (Xu et al., 2023) Wizard 7B Uncensored (Xu et al., 2023) Wizard 13B Uncensored (Xu et al., 2023) GPT4-x-Vicuna-13b (Nous-Research, 2023a) Falcon 7b (Almazrouei et al., 2023) Falcon 7b instruct (Almazrouei et al., 2023)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            76.84399999999994,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            76.84399999999994,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            233.36174060000002,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            233.36174060000002,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023noushermes\",\n",
      "          \"start_index\": 177\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.nousresearch2023noushermes\",\n",
      "          \"start_index\": 192\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023noushermesllama\",\n",
      "          \"start_index\": 213\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.nousresearch2023noushermesllama\",\n",
      "          \"start_index\": 228\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023redmondpuffin\",\n",
      "          \"start_index\": 247\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023d\",\n",
      "          \"url\": \"cite.nousresearch2023redmondpuffin\",\n",
      "          \"start_index\": 262\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Conoveretal .,\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV1\",\n",
      "          \"start_index\": 280\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV1\",\n",
      "          \"start_index\": 296\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Conoveretal .,\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 315\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 331\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Taorietal .,\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 350\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 364\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Wang\",\n",
      "          \"url\": \"cite.alpaca-lora\",\n",
      "          \"start_index\": 387\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.alpaca-lora\",\n",
      "          \"start_index\": 393\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"WangandKomatsuzaki\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 412\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 434\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Touvronetal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 451\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 467\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Touvronetal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 485\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 501\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Bidermanetal .,\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 521\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 538\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Bidermanetal .,\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 557\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 574\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhengetal .,\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 594\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 608\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhengetal .,\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 635\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 649\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhengetal .,\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 677\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 691\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 717\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 731\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 754\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 768\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 790\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 804\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Gengetal .,\",\n",
      "          \"url\": \"cite.koala_blogpost_2023\",\n",
      "          \"start_index\": 822\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koala_blogpost_2023\",\n",
      "          \"start_index\": 835\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MosaicML - Team\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 882\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 897\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MosaicML - Team\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 924\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 939\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MosaicML - Team\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 962\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 977\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Xuetal .,\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 994\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1005\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Xuetal .,\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1033\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1044\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Xuetal .,\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1073\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1084\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023gpt4xvicuna\",\n",
      "          \"start_index\": 1109\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.nousresearch2023gpt4xvicuna\",\n",
      "          \"start_index\": 1124\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Almazroueietal .,\",\n",
      "          \"url\": \"cite.falcon40b\",\n",
      "          \"start_index\": 1142\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.falcon40b\",\n",
      "          \"start_index\": 1161\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"863cef5b45ff3c135f3d6ac488541345\",\n",
      "    \"text\": \"73.4 74 74.8 73.6 68.6 73.1 83.3 77.6 79.5 83.9 81.5 68.8 56.7 73.9 74.3 65.4 73.1 68.5 63.5 67.7 81.5 76.6 81.5 82.3 62.5 60.1 76.5 67.9 74.8 74.3 77.1 78.4 77.7 78.4 81.3 73.6 70.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            249.19727459999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            249.19727459999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            264.01735,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            264.01735,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9292384de68d6f41f3b383a7321eceeb\",\n",
      "    \"text\": \"74.8 75.1 74.9 74.3 75.8 77.6 79.2 79.8 78.9 80.7 80.7 77.3 75.4 77.2 79.3 76.2 77.4 79.1 76.3 76.6 64.6 77.2 76.8 78.6 71.2 67.4 77.9 78 79.3 80.4 78.2 77.2 74.2 75.5 75 80.7 78.6\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            282.32399999999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            282.32399999999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            297.14494840000003,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            297.14494840000003,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2e76b593bee43831923f1d8063243e50\",\n",
      "    \"text\": \"63.4 63.2 63.6 63.8 66.2 72.1 75 74.9 80 80.1 80.4 67.6 71 73.9 74 66.2 73 76.2 64 67.3 46.3 70.7 73.3 74.1 53.6 41.2 72.6 68.1 76.3 77.2 74.5 69.9 68 72.1 75.2 76.3 69.8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.6919094,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            322.6919094,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            337.51335,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            337.51335,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e4cc6d4975ff77e2c54a0df8341aff4c\",\n",
      "    \"text\": \"64.7 63.6 63.8 63.5 63.5 67.8 71.3 70.1 71.9 71.3 72.5 63.9 62.2 66.1 68.8 64.1 66.9 70.1 61.1 63.8 61.8 67.3 66.7 70.9 54.8 50.1 68.8 65 68.6 67.8 67.5 66.5 65.2 69.5 65 67.3 66.7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            366.54024899999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            366.54024899999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            381.36168960000003,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            381.36168960000003,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"61bf0aa152722b826ff22a41233dc20c\",\n",
      "    \"text\": \"54.9 55.4 56.6 57.7 56.4 51.1 60.9 67.9 74.2 75.7 77.6 62.9 64.6 59.8 56.6 62.2 52.5 60 61.3 63.9 49.3 53.5 57.4 61 52.4 44.9 54.3 64.2 70 72.2 69.4 56.8 53.5 57.5 58.7 71 67.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            403.84267,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            403.84267,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            418.6641106,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            418.6641106,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3ba922161513605086db41d4457e0843\",\n",
      "    \"text\": \"36 34.9 35.3 35 35.7 40.4 44.2 43.4 50.9 52.1 50.7 38.7 38.5 43.3 43.9 36.6 41.4 44.6 35.2 34.8 33.3 41.2 42.7 43.5 31.1 27 41 40.4 42.2 44.6 43.3 40.5 38.7 40.4 43.9 43.3 42.7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            439.78999999999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            439.78999999999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            454.6116196,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            454.6116196,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"06b88051ebb9bf06a22ceb08cda91320\",\n",
      "    \"text\": \"40.2 38.4 41 38.8 40.2 40.2 43.4 42.6 46.4 46.2 45.6 41.2 40.4 43.4 42.6 38.2 42.4 42.2 37.2 38 39.4 40.8 43.6 44.4 33.4 32 42.8 43.2 42.6 43 44.2 42.6 41.6 44 43.6 44.4 41.2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            475.736,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            475.736,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            490.5591286,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            490.5591286,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "    \"text\": \"text-davinci-003\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            76.844,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            76.844,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            132.522415,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            132.522415,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f205dfd163738d0912bd2e3793e41a8e\",\n",
      "    \"text\": \"88.1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            249.1972746,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            249.1972746,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            264.0166246,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            264.0166246,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9f70060bfc2e03397be9c3ca01669dbb\",\n",
      "    \"text\": \"83.8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            282.324873,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            282.324873,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            297.14422300000007,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            297.14422300000007,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"efa84942a23a7f4f32030613b47e5d14\",\n",
      "    \"text\": \"83.4\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.69278240000006,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            322.69278240000006,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            337.5121324000001,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            337.5121324000001,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3e22defdcd8953213ed2b41bc15e9400\",\n",
      "    \"text\": \"75.8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            366.5411220000001,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            366.5411220000001,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            381.36047200000013,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            381.36047200000013,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"dd3373b1f28a16333af2e3b8484ac102\",\n",
      "    \"text\": \"83.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            403.8435430000001,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            403.8435430000001,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            418.66289300000017,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            418.66289300000017,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c73cb5d9dc355215c7df2c742d6c06c0\",\n",
      "    \"text\": \"63.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            439.79105200000015,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            439.79105200000015,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            454.6104020000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            454.6104020000002,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"349d5830083c52f2e022ef9572f77a8c\",\n",
      "    \"text\": \"51.0\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            475.7385610000002,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            475.7385610000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            490.5579110000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            490.5579110000002,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e4cfa78e74e08ab87de711c67c176fb4\",\n",
      "    \"text\": \"Table 1: Evaluations of all language models in the GPT4All ecosystem as of August 1, 2023. Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4All ecosystem, Nous-Hermes2, achieves over 92% of the average performance of text-davinci-003. Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy. Note that at release, GPT4All-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.557,\n",
      "            668.5213216\n",
      "          ],\n",
      "          [\n",
      "            70.557,\n",
      "            738.2599216\n",
      "          ],\n",
      "          [\n",
      "            525.6547547729999,\n",
      "            738.2599216\n",
      "          ],\n",
      "          [\n",
      "            525.6547547729999,\n",
      "            668.5213216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c0c82e3e53fb3495e4493442d86113aa\",\n",
      "    \"text\": \"58.2 57.8 58.6 58.1 58.1 60.3 65.3 65.2 68.8 70.0 69.9 60.1 58.4 62.5 62.8 58.4 61.0 63.0 56.9 58.9 53.7 61.0 63.1 65.0 51.3 46.1 62.0 61.0 64.8 65.6 64.9 61.7 59.8 62.5 63.2 65.2 62.5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            507.7219004,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            507.7219004,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            522.5435200000001,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            522.5435200000001,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"0955591427ee44e2be8e6cd3b9d8d95b\",\n",
      "    \"text\": \"75.7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            507.7229524000002,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            507.7229524000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            522.5423024000003,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            522.5423024000003,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5b851cfc3a92040f34538dabb304f77b\",\n",
      "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4All achieved and maintains faster ecosystem growth due to the focus on access, which allows more users to meaningfully participate.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            285.4943215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            319.36792160000005\n",
      "          ],\n",
      "          [\n",
      "            524.4125679919997,\n",
      "            319.36792160000005\n",
      "          ],\n",
      "          [\n",
      "            524.4125679919997,\n",
      "            285.4943215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d19fcb87b6dfe6f1efe8ff69aedf0a8a\",\n",
      "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            343.8763216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            413.61492159999995\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            413.61492159999995\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            343.8763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6fdeb55e51d9b4b32895af473bd3970f\",\n",
      "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware. Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            304.817,\n",
      "            343.8763216\n",
      "          ],\n",
      "          [\n",
      "            304.817,\n",
      "            401.65992159999996\n",
      "          ],\n",
      "          [\n",
      "            526.0636575760001,\n",
      "            401.65992159999996\n",
      "          ],\n",
      "          [\n",
      "            526.0636575760001,\n",
      "            343.8763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b19cd88bad15dbd896f39128b97e30bc\",\n",
      "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4All also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4All user data is collected on an opt in basis.) GPT4All has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others. GPT4All is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            416.6453216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            641.8009216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400003,\n",
      "            641.8009216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400003,\n",
      "            416.6453216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"),\",\n",
      "          \"url\": \"table.caption.2\",\n",
      "          \"start_index\": 93\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Chase\",\n",
      "          \"url\": \"cite.langchain\",\n",
      "          \"start_index\": 679\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.langchain\",\n",
      "          \"start_index\": 686\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"imartinez\",\n",
      "          \"url\": \"cite.privategpt\",\n",
      "          \"start_index\": 758\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.privategpt\",\n",
      "          \"start_index\": 769\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"StanGi\",\n",
      "          \"url\": \"cite.stangirard2023quivr\",\n",
      "          \"start_index\": 784\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"rard\",\n",
      "          \"url\": \"cite.stangirard2023quivr\",\n",
      "          \"start_index\": 792\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stangirard2023quivr\",\n",
      "          \"start_index\": 798\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MindsDB\",\n",
      "          \"url\": \"cite.mindsdb\",\n",
      "          \"start_index\": 818\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.mindsdb\",\n",
      "          \"start_index\": 827\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Leo\",\n",
      "          \"url\": \"cite.leo_github_fastest\",\n",
      "          \"start_index\": 914\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.leo_github_fastest\",\n",
      "          \"start_index\": 919\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5dc00f8cd1386b82aa9564922875f55b\",\n",
      "    \"text\": \"4 The Future of GPT4All\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            656.7605159\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            668.7156159\n",
      "          ],\n",
      "          [\n",
      "            208.469201,\n",
      "            668.7156159\n",
      "          ],\n",
      "          [\n",
      "            208.469201,\n",
      "            656.7605159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8715e02bb2e5b4d7758a80a9775e8168\",\n",
      "    \"text\": \"In the future, we will continue to grow GPT4All, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models. Fur- thermore, we will expand the set of hardware devices that GPT4All models run on, so that GPT4All models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.617,\n",
      "            679.5273216\n",
      "          ],\n",
      "          [\n",
      "            70.617,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400015,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400015,\n",
      "            679.5273216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"5dc00f8cd1386b82aa9564922875f55b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
      "    \"text\": \"Limitations\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            416.61951589999995\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            428.57461589999997\n",
      "          ],\n",
      "          [\n",
      "            365.2599695,\n",
      "            428.57461589999997\n",
      "          ],\n",
      "          [\n",
      "            365.2599695,\n",
      "            416.61951589999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f07b7060b90e509a5831047a04041324\",\n",
      "    \"text\": \"By enabling access to large language models, the GPT4All project also inherits many of the ethical con- cerns associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons). While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups. We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            439.3863216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            604.7649216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            604.7649216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            439.3863216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"037ae7c81d992d8bc0727fa73e581faf\",\n",
      "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4All open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4All effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as- signment, and hope to be able to support some of this research ourselves in the future.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            607.7963216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            761.2209216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520002,\n",
      "            761.2209216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520002,\n",
      "            607.7963216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d3f115969fa159c8ae83287b2de7a62e\",\n",
      "    \"text\": \"References\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            72.36851589999992\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            84.32361589999994\n",
      "          ],\n",
      "          [\n",
      "            126.4093946,\n",
      "            84.32361589999994\n",
      "          ],\n",
      "          [\n",
      "            126.4093946,\n",
      "            72.36851589999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "    \"text\": \"Nomic AI. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            92.14289239999994\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            102.5239216\n",
      "          ],\n",
      "          [\n",
      "            286.13765,\n",
      "            102.5239216\n",
      "          ],\n",
      "          [\n",
      "            286.13765,\n",
      "            92.14289239999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Atlas\",\n",
      "          \"url\": \"https://atlas.nomic.ai/\",\n",
      "          \"start_index\": 16\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :// atlas . nomic . ai\",\n",
      "          \"url\": \"https://atlas.nomic.ai/\",\n",
      "          \"start_index\": 23\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c786e482f15da16d5c8387f40291180e\",\n",
      "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            112.95932159999995\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            188.67592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.8761733600001,\n",
      "            188.67592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.8761733600001,\n",
      "            112.95932159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ff41e3dc2250ba1bdf97a74f6b347927\",\n",
      "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. https://github.com/nomic-ai/gpt4all.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            199.1103215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            252.90892159999999\n",
      "          ],\n",
      "          [\n",
      "            290.88095540800003,\n",
      "            252.90892159999999\n",
      "          ],\n",
      "          [\n",
      "            290.88095540800003,\n",
      "            199.1103215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com / nomic - ai / gpt4all\",\n",
      "          \"url\": \"https://github.com/nomic-ai/gpt4all\",\n",
      "          \"start_index\": 196\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6b1e1363d133a804d6a87d3d9ea1bc5e\",\n",
      "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            263.34432159999994\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            273.3069216\n",
      "          ],\n",
      "          [\n",
      "            289.4846169432001,\n",
      "            273.3069216\n",
      "          ],\n",
      "          [\n",
      "            289.4846169432001,\n",
      "            263.34432159999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"https://www.bbc.com/news/technology-65139406\",\n",
      "          \"start_index\": 14\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8f4f477e26112f0d2d24d57229527002\",\n",
      "    \"text\": \"concerns. BBC News.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            274.0741818\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            284.26592160000007\n",
      "          ],\n",
      "          [\n",
      "            172.53465,\n",
      "            284.26592160000007\n",
      "          ],\n",
      "          [\n",
      "            172.53465,\n",
      "            274.0741818\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"concerns\",\n",
      "          \"url\": \"https://www.bbc.com/news/technology-65139406\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9ecc6cb3f818c8971fbbebf3ada09d7b\",\n",
      "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            294.7013215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            370.41692159999997\n",
      "          ],\n",
      "          [\n",
      "            290.8793613920001,\n",
      "            370.41692159999997\n",
      "          ],\n",
      "          [\n",
      "            290.8793613920001,\n",
      "            294.7013215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Pythia\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.01373\",\n",
      "          \"start_index\": 239\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"modelsacrosstrainingandscaling\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.01373\",\n",
      "          \"start_index\": 284\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"8f4f477e26112f0d2d24d57229527002\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"16f9306e183f011f9a89e80c8b1d4f1c\",\n",
      "    \"text\": \"Harrison Chase. 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            380.8523216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            163.318529496,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            163.318529496,\n",
      "            380.8523216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"27d06343168776257e5cdc6d77525580\",\n",
      "    \"text\": \"langchain. https://github.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            169.58839218000003,\n",
      "            380.4338924\n",
      "          ],\n",
      "          [\n",
      "            169.58839218000003,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            380.4338924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github\",\n",
      "          \"url\": \"https://github.com/langchain-ai/langchain\",\n",
      "          \"start_index\": 11\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "    \"text\": \"com/langchain-ai/langchain.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            391.3928924\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            401.7739216\n",
      "          ],\n",
      "          [\n",
      "            218.31365,\n",
      "            401.7739216\n",
      "          ],\n",
      "          [\n",
      "            218.31365,\n",
      "            391.3928924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"com / langchain - ai / langchain\",\n",
      "          \"url\": \"https://github.com/langchain-ai/langchain\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3a06407710f1e1db5c1e2561578c6241\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            412.20932159999995\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            466.00692159999994\n",
      "          ],\n",
      "          [\n",
      "            290.79149126000016,\n",
      "            466.00692159999994\n",
      "          ],\n",
      "          [\n",
      "            290.79149126000016,\n",
      "            412.20932159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Hellodolly\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
      "          \"start_index\": 132\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Democratizingthemagicofchatgptwithopenmod\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
      "          \"start_index\": 145\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"els\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
      "          \"start_index\": 195\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e4992de073d64de58bd155d44d670bad\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned llm.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            476.4423216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            530.2409216\n",
      "          ],\n",
      "          [\n",
      "            290.78760584600013,\n",
      "            530.2409216\n",
      "          ],\n",
      "          [\n",
      "            290.78760584600013,\n",
      "            476.4423216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Freedolly\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
      "          \"start_index\": 140\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Introducingtheworld \\u2019 sfirsttrulyopeninstruction\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
      "          \"start_index\": 152\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"tunedllm\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
      "          \"start_index\": 205\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"056cbfffc020bf8a655a5197701034c3\",\n",
      "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- lace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            540.6763215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            583.5149216\n",
      "          ],\n",
      "          [\n",
      "            290.8736030092001,\n",
      "            583.5149216\n",
      "          ],\n",
      "          [\n",
      "            290.8736030092001,\n",
      "            540.6763215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Koala : Adialoguemodelforacademicre\",\n",
      "          \"url\": \"https://bair.berkeley.edu/blog/2023/04/03/koala/\",\n",
      "          \"start_index\": 107\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"search\",\n",
      "          \"url\": \"https://bair.berkeley.edu/blog/2023/04/03/koala/\",\n",
      "          \"start_index\": 148\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e21f882269851b2f6a4a5411c7f2e8fc\",\n",
      "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            593.9503216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            636.7899216\n",
      "          ],\n",
      "          [\n",
      "            289.13354754680006,\n",
      "            636.7899216\n",
      "          ],\n",
      "          [\n",
      "            289.13354754680006,\n",
      "            593.9503216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Lora\",\n",
      "          \"url\": \"http://arxiv.org/abs/2106.09685\",\n",
      "          \"start_index\": 117\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"largelanguagemodels\",\n",
      "          \"url\": \"http://arxiv.org/abs/2106.09685\",\n",
      "          \"start_index\": 146\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3ea6c2ee4f5b756e77b23cdcbaf6d74c\",\n",
      "    \"text\": \"imartinez. 2023. privategpt. https://github.com/\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            646.8068923999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            657.1879216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            657.1879216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            646.8068923999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com\",\n",
      "          \"url\": \"https://github.com/imartinez/privateGPT\",\n",
      "          \"start_index\": 29\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0d84c182bf003f976d44d475b40751e3\",\n",
      "    \"text\": \"imartinez/privateGPT.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            657.7658924\n",
      "          ],\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            668.1469216\n",
      "          ],\n",
      "          [\n",
      "            187.92665000000002,\n",
      "            668.1469216\n",
      "          ],\n",
      "          [\n",
      "            187.92665000000002,\n",
      "            657.7658924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"imartinez / privateGPT\",\n",
      "          \"url\": \"https://github.com/imartinez/privateGPT\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"113ed8473136e587a63ff658d9685446\",\n",
      "    \"text\": \"Oscar Leo. 2023. GitHub: The Fastest Growing Repos-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            678.5823216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            688.5449216\n",
      "          ],\n",
      "          [\n",
      "            290.7856627650001,\n",
      "            688.5449216\n",
      "          ],\n",
      "          [\n",
      "            290.7856627650001,\n",
      "            678.5823216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"GitHub : TheFastestGrowingRepos\",\n",
      "          \"url\": \"https://levelup.gitconnected.com/github-the-fastest-growing-repositories-of-all-time-f9884eb79e9\",\n",
      "          \"start_index\": 17\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bfac0e2a1a1b97d79ec43a400d81572e\",\n",
      "    \"text\": \"itories of All Time.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            689.5403216\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            699.5029216\n",
      "          ],\n",
      "          [\n",
      "            162.39250619999999,\n",
      "            699.5029216\n",
      "          ],\n",
      "          [\n",
      "            162.39250619999999,\n",
      "            689.5403216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"itoriesofAllTime\",\n",
      "          \"url\": \"https://levelup.gitconnected.com/github-the-fastest-growing-repositories-of-all-time-f9884eb79e9\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"23ac2d2fe4e15d8b26e950649c9ae26c\",\n",
      "    \"text\": \"Robert McMillan. 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            709.9383216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            741.8189216\n",
      "          ],\n",
      "          [\n",
      "            289.138158692,\n",
      "            741.8189216\n",
      "          ],\n",
      "          [\n",
      "            289.138158692,\n",
      "            709.9383216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \". powerfulaiinthehandsofeveryone .\",\n",
      "          \"url\": \"https://www.wsj.com/articles/a-meta-platforms-leak-put-powerful-ai-in-the-hands-of-everyone-8b9f875a\",\n",
      "          \"start_index\": 21\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"powerfulaiinthehandsofeveryone\",\n",
      "          \"url\": \"https://www.wsj.com/articles/a-meta-platforms-leak-put-powerful-ai-in-the-hands-of-everyone-8b9f875a\",\n",
      "          \"start_index\": 49\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bfac0e2a1a1b97d79ec43a400d81572e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"afc0a061d59bc2dd31c7c5ce76ee55e4\",\n",
      "    \"text\": \"MindsDB. 2023. Mindsdb. https://github.com/\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            751.8358923999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            762.2169216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            762.2169216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            751.8358923999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com\",\n",
      "          \"url\": \"https://github.com/mindsdb/mindsdb\",\n",
      "          \"start_index\": 24\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"eb547b2c0d2a1977932d2e99c28c07ea\",\n",
      "    \"text\": \"mindsdb/mindsdb. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            762.7948924\n",
      "          ],\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            241.22706000000002,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            241.22706000000002,\n",
      "            762.7948924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ec3f3280237ca8fe7a71d94be4c52569\",\n",
      "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms. Accessed: 2023-08-07.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            105.89492159999998\n",
      "          ],\n",
      "          [\n",
      "            526.1496030092002,\n",
      "            105.89492159999998\n",
      "          ],\n",
      "          [\n",
      "            526.1496030092002,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Introducingmpt - 7b : standardforopen - source , commerciallyusablellms\",\n",
      "          \"url\": null,\n",
      "          \"start_index\": 21\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"standardforopen - source , commerciallyusablellms\",\n",
      "          \"url\": null,\n",
      "          \"start_index\": 47\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"eb547b2c0d2a1977932d2e99c28c07ea\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"691d7fdf7080b720f8a8071e195b16ae\",\n",
      "    \"text\": \"Nous-Research.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            116.8363215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            116.8363215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f827e63fb077c922bdb201badf9538dc\",\n",
      "    \"text\": \"2023a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            383.768387428,\n",
      "            116.8363215999999\n",
      "          ],\n",
      "          [\n",
      "            383.768387428,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            411.144416716,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            411.144416716,\n",
      "            116.8363215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"691d7fdf7080b720f8a8071e195b16ae\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"836334aabadbdf6ca8aceb81f73d1164\",\n",
      "    \"text\": \"gpt4-x-vicuna-13b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            448.37744244400005,\n",
      "            116.8363215999999\n",
      "          ],\n",
      "          [\n",
      "            448.37744244400005,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            116.8363215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7d1236630fbec2f7f81c116ade9d829d\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            127.37689239999997\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            148.7159216\n",
      "          ],\n",
      "          [\n",
      "            512.8067844000001,\n",
      "            148.7159216\n",
      "          ],\n",
      "          [\n",
      "            512.8067844000001,\n",
      "            127.37689239999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// huggingface . co / NousResearch gpt4 - x - vicuna - 13b . ModelonHuggingFace\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/gpt4-x-vicuna-13b\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ad50d6c212c9ead7c7d08664b1f0a368\",\n",
      "    \"text\": \"Nous-Research.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            159.65732159999993\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            159.65732159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8f1a2b95024fc5a8a5b3a5142706fb6f\",\n",
      "    \"text\": \"2023b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            384.306965584,\n",
      "            159.65732159999993\n",
      "          ],\n",
      "          [\n",
      "            384.306965584,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            412.252058584,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            412.252058584,\n",
      "            159.65732159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ad50d6c212c9ead7c7d08664b1f0a368\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9bb17e6c8fda36fc71499b4fe0441a98\",\n",
      "    \"text\": \"Nous-hermes-13b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            451.20243730000004,\n",
      "            159.65732159999993\n",
      "          ],\n",
      "          [\n",
      "            451.20243730000004,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            159.65732159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fe871a36f9b133dd10e75d7e9343bd26\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ Nous-Hermes-13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            170.1978924\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            191.5379216\n",
      "          ],\n",
      "          [\n",
      "            502.34578440000007,\n",
      "            191.5379216\n",
      "          ],\n",
      "          [\n",
      "            502.34578440000007,\n",
      "            170.1978924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2c04966d0258539a0b71703eea37b41f\",\n",
      "    \"text\": \"Nous-Research. 2023c.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            202.47832159999996\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            404.823744772,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            404.823744772,\n",
      "            202.47832159999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8328bea0ed9a308f513b89b4809d19f0\",\n",
      "    \"text\": \"Nous-hermes-llama-2-7b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            421.855008724,\n",
      "            202.47832159999996\n",
      "          ],\n",
      "          [\n",
      "            421.855008724,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            202.47832159999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"81055478269ce81b5561884c98424677\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            213.0188923999999\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            245.31792159999998\n",
      "          ],\n",
      "          [\n",
      "            524.408199856,\n",
      "            245.31792159999998\n",
      "          ],\n",
      "          [\n",
      "            524.408199856,\n",
      "            213.0188923999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// huggingface . co / NousResearch\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\",\n",
      "          \"start_index\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Hermes - llama - 2 - 7b\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\",\n",
      "          \"start_index\": 37\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"95738f8b6f648f2d97a991304ccb420e\",\n",
      "    \"text\": \"Nous-Research.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            256.2593215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            256.2593215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2484431e07b97b4f98a6ac8d59303d97\",\n",
      "    \"text\": \"2023d.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            381.268571836,\n",
      "            256.2593215999999\n",
      "          ],\n",
      "          [\n",
      "            381.268571836,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            409.213664836,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            409.213664836,\n",
      "            256.2593215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"95738f8b6f648f2d97a991304ccb420e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0d0a73807f488d425d129e474ce8114a\",\n",
      "    \"text\": \"Redmond-puffin-13b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            438.459474892,\n",
      "            256.2593215999999\n",
      "          ],\n",
      "          [\n",
      "            438.459474892,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            256.2593215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c3c419152e30de95467de68011b36673\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ Redmond-Puffin-13B. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            266.7988924\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            288.1389216\n",
      "          ],\n",
      "          [\n",
      "            517.2897843999999,\n",
      "            288.1389216\n",
      "          ],\n",
      "          [\n",
      "            517.2897843999999,\n",
      "            266.7988924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// huggingface . co / NousResearch Redmond - Puffin - 13B . ModelonHuggingFace\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/Redmond-Puffin-13B\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f4154c37f41040e7f7b5dd83d6bb9f7d\",\n",
      "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            299.08032159999993\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            309.0429216\n",
      "          ],\n",
      "          [\n",
      "            459.6855912000001,\n",
      "            309.0429216\n",
      "          ],\n",
      "          [\n",
      "            459.6855912000001,\n",
      "            299.08032159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Gpt - 4technicalreport\",\n",
      "          \"url\": \"http://arxiv.org/abs/2303.08774\",\n",
      "          \"start_index\": 14\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0a537655c8ca57a623a7fa87b3193a18\",\n",
      "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Ab- heesht Sharma, Andrea Santilli, Thibault Fevry, Ja- son Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            319.98332159999995\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            483.3709216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            483.3709216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            319.98332159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"http://arxiv.org/abs/2110.08207\",\n",
      "          \"start_index\": 629\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"zero - shottaskgeneralization\",\n",
      "          \"url\": \"http://arxiv.org/abs/2110.08207\",\n",
      "          \"start_index\": 667\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"f4154c37f41040e7f7b5dd83d6bb9f7d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"886a7f467ba741ee5d07336e15bca148\",\n",
      "    \"text\": \"Stability-AI. 2023. Stablelm. https://github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            493.89389239999997\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            515.2339216\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            515.2339216\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            493.89389239999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com\",\n",
      "          \"url\": \"https://github.com/Stability-AI/StableLM\",\n",
      "          \"start_index\": 30\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI / StableLM\",\n",
      "          \"url\": \"https://github.com/Stability-AI/StableLM\",\n",
      "          \"start_index\": 50\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6161d90c7111121c9df590576b63d8d2\",\n",
      "    \"text\": \"https://github.com/\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            430.761,\n",
      "            525.7558924\n",
      "          ],\n",
      "          [\n",
      "            430.761,\n",
      "            535.7184924000001\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            535.7184924000001\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            525.7558924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"14880807bec39d9525429193f10ca671\",\n",
      "    \"text\": \"StanGirard. 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            526.1743216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            536.1369216\n",
      "          ],\n",
      "          [\n",
      "            381.563265544,\n",
      "            536.1369216\n",
      "          ],\n",
      "          [\n",
      "            381.563265544,\n",
      "            526.1743216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "    \"text\": \"quivr. StanGirard/quivr. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            526.1743216\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            547.0959216\n",
      "          ],\n",
      "          [\n",
      "            481.48406000000006,\n",
      "            547.0959216\n",
      "          ],\n",
      "          [\n",
      "            481.48406000000006,\n",
      "            526.1743216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f9127289b648f97d5468d9c534385556\",\n",
      "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            558.0373216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            611.8349216\n",
      "          ],\n",
      "          [\n",
      "            525.7912084368,\n",
      "            611.8349216\n",
      "          ],\n",
      "          [\n",
      "            525.7912084368,\n",
      "            558.0373216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https\",\n",
      "          \"url\": \"https://github.com/tatsu-lab/stanford_alpaca\",\n",
      "          \"start_index\": 189\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"github . com / tatsu - lab / stanford _ alpaca\",\n",
      "          \"url\": \"https://github.com/tatsu-lab/stanford_alpaca\",\n",
      "          \"start_index\": 198\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1e03777b59eb46b371e2c0ec4e04c04c\",\n",
      "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            622.7763216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            698.4919216\n",
      "          ],\n",
      "          [\n",
      "            526.1521733600001,\n",
      "            698.4919216\n",
      "          ],\n",
      "          [\n",
      "            526.1521733600001,\n",
      "            622.7763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Llama\",\n",
      "          \"url\": \"http://arxiv.org/abs/2302.13971\",\n",
      "          \"start_index\": 238\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"models\",\n",
      "          \"url\": \"http://arxiv.org/abs/2302.13971\",\n",
      "          \"start_index\": 283\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb3d4cb151a83b755fbb5d192919a87a\",\n",
      "    \"text\": \"The Verge. 2023. Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            709.4333216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            730.3549216\n",
      "          ],\n",
      "          [\n",
      "            526.15332765,\n",
      "            730.3549216\n",
      "          ],\n",
      "          [\n",
      "            526.15332765,\n",
      "            709.4333216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Meta \\u2019 hasleakedonline \\u2014 whathappensnow ? TheVerge\",\n",
      "          \"url\": \"https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\",\n",
      "          \"start_index\": 17\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"hasleakedonline \\u2014 whathappensnow ?\",\n",
      "          \"url\": \"https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\",\n",
      "          \"start_index\": 51\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e3c968af341f5c57d0f600fc18d74a87\",\n",
      "    \"text\": \"James Vincent. 2023. As an ai generated language model: The phrase that shows how ai is polluting the web. The Verge.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            741.2953216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            524.4084191080001,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            524.4084191080001,\n",
      "            741.2953216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \". model : theweb . TheVerge\",\n",
      "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
      "          \"start_index\": 19\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"model : theweb . TheVerge\",\n",
      "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
      "          \"start_index\": 49\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"theweb\",\n",
      "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
      "          \"start_index\": 98\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"056688ab6012c536a7138e0807ad0938\",\n",
      "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A 6 Billion Parameter Autoregressive Language https://github.com/kingoflolz/ Model. mesh-transformer-jax.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            116.85392159999992\n",
      "          ],\n",
      "          [\n",
      "            290.5144309800001,\n",
      "            116.85392159999992\n",
      "          ],\n",
      "          [\n",
      "            290.5144309800001,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com / kingoflolz\",\n",
      "          \"url\": \"https://github.com/kingoflolz/mesh-transformer-jax\",\n",
      "          \"start_index\": 93\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"mesh - transformer - jax\",\n",
      "          \"url\": \"https://github.com/kingoflolz/mesh-transformer-jax\",\n",
      "          \"start_index\": 131\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "    \"text\": \"Eric J. Wang. 2023. alpaca-lora. https://github. com/tloen/alpaca-lora. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            125.40089239999998\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            146.74092159999998\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            146.74092159999998\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            125.40089239999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github\",\n",
      "          \"url\": \"https://github.com/tloen/alpaca-lora\",\n",
      "          \"start_index\": 33\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"com / tloen / alpaca - lora\",\n",
      "          \"url\": \"https://github.com/tloen/alpaca-lora\",\n",
      "          \"start_index\": 49\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9e1872a7627d65000001f6a1a6cdd620\",\n",
      "    \"text\": \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- naneh Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            155.7063215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            198.54592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.784716692,\n",
      "            198.54592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.784716692,\n",
      "            155.7063215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Self - instruct : Aligninglan\",\n",
      "          \"url\": \"http://arxiv.org/abs/2212.10560\",\n",
      "          \"start_index\": 121\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"guagemodelswithself - generatedinstructions\",\n",
      "          \"url\": \"http://arxiv.org/abs/2212.10560\",\n",
      "          \"start_index\": 150\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1d4f3165609e78d1d6fb3065ae898420\",\n",
      "    \"text\": \"Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            207.51132159999997\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            250.3509216\n",
      "          ],\n",
      "          [\n",
      "            290.3823269040001,\n",
      "            250.3509216\n",
      "          ],\n",
      "          [\n",
      "            290.3823269040001,\n",
      "            207.51132159999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Wizardlm\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.12244\",\n",
      "          \"start_index\": 106\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"modelstofollowcomplexinstructions\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.12244\",\n",
      "          \"start_index\": 142\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7ef5091817209ce37c6cfb895b7c8acd\",\n",
      "    \"text\": \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            259.3163215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            313.1139216\n",
      "          ],\n",
      "          [\n",
      "            290.37824261200007,\n",
      "            313.1139216\n",
      "          ],\n",
      "          [\n",
      "            290.37824261200007,\n",
      "            259.3163215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-03T13:31:00\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"http://arxiv.org/abs/2306.05685\",\n",
      "          \"start_index\": 184\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"llm - as - a - judgewithmt - benchandchatbotarena\",\n",
      "          \"url\": \"http://arxiv.org/abs/2306.05685\",\n",
      "          \"start_index\": 194\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in elements]\n",
    "output = json.dumps(element_dict, indent=2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NarrativeText', 'Title', 'UncategorizedText'}\n"
     ]
    }
   ],
   "source": [
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We don't see `Table`, table information is not extracted as we expected, lets use different strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table extraction from PDF\n",
    "- Now let’s say that your PDF has tables and let’s say you want to preserve the structure of the tables. \n",
    "- You will have to specify the [strategy](https://unstructured-io.github.io/unstructured/best_practices/strategies.html) parameter as `hi_res`. This will use a combination of computer vision and Optical Character Recognition (OCR) to extract the tables and maintain the structure. \n",
    "It will return both the text and the html of the table. This is super useful for rendering the tables or passing to a LLM.\n",
    "\n",
    "> Note: For even better table extraction Unstructured offers an API that improves upon the existing open source models.\n",
    "\n",
    "> Depending upon machine, you might face different module / library issues, these links might help\n",
    "- https://stackoverflow.com/questions/59690698/modulenotfounderror-no-module-named-lzma-when-building-python-using-pyenv-on\n",
    "- https://unstructured-io.github.io/unstructured/installation/full_installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st way\n",
    "\n",
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(filename=filename,\n",
    "                     strategy='hi_res',\n",
    "           )\n",
    "\n",
    "tables = [el for el in elements if el.category == \"Table\"]\n",
    "\n",
    "print(tables[0].text)\n",
    "print(tables[0].metadata.text_as_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd way \n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "elements = partition_pdf(filename=filename,\n",
    "                         infer_table_structure=True,\n",
    "                         strategy='hi_res',\n",
    "           )\n",
    "\n",
    "tables = [el for el in elements if el.category == \"Table\"]\n",
    "\n",
    "print(tables[0].text)\n",
    "print(tables[0].metadata.text_as_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, lets use python sdk to do the same -> [link](https://unstructured-io.github.io/unstructured/api.html)\n",
    "- For SAAS API, visit this [link](https://unstructured.io/api-key-hosted)\n",
    "- For Free Unstructured API, visit this [link](https://docs.unstructured.io/api-reference/api-services/free-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "saas_api_key_auth = os.environ.get('saas_api_key_auth')\n",
    "saas_server_url = os.environ.get('saas_server_url')\n",
    "free_api_key_auth = os.environ.get('free_api_key_auth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = UnstructuredClient(\n",
    "    api_key_auth=free_api_key_auth\n",
    "    #api_key_auth=saas_api_key_auth,\n",
    "    #server_url=saas_server_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd way \n",
    "\n",
    "with open(filename, \"rb\") as f:\n",
    "    files=shared.Files(\n",
    "        content=f.read(),\n",
    "        file_name=filename,\n",
    "    )\n",
    "\n",
    "req = shared.PartitionParameters(\n",
    "    files=files,\n",
    "    strategy=\"hi_res\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    skip_infer_table_types=[],\n",
    "    pdf_infer_table_structure=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    resp = client.general.partition(req)\n",
    "    elements = dict_to_elements(resp.elements)\n",
    "except SDKError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [el for el in elements if el.category == \"Table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Table at 0x38ac04a50>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model BoolQ PIQA HellaSwag WinoG. ARC-e ARC-c OBQA Avg. GPT4All-J 6B v1.0* GPT4All-J v1.1-breezy* GPT4All-J v1.2-jazzy* GPT4All-J v1.3-groovy* GPT4All-J Lora 6B* GPT4All LLaMa Lora 7B* GPT4All 13B snoozy* GPT4All Falcon Nous-Hermes (Nous-Research, 2023b) Nous-Hermes2 (Nous-Research, 2023c) Nous-Puffin (Nous-Research, 2023d) Dolly 6B* (Conover et al., 2023a) Dolly 12B* (Conover et al., 2023b) Alpaca 7B* (Taori et al., 2023) Alpaca Lora 7B* (Wang, 2023) GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B* (Touvron et al., 2023) LLama 13B* (Touvron et al., 2023) Pythia 6.7B* (Biderman et al., 2023) Pythia 12B* (Biderman et al., 2023) Fastchat T5* (Zheng et al., 2023) Fastchat Vicuña* 7B (Zheng et al., 2023) Fastchat Vicuña 13B* (Zheng et al., 2023) StableVicuña RLHF* (Stability-AI, 2023) StableLM Tuned* (Stability-AI, 2023) StableLM Base* (Stability-AI, 2023) Koala 13B* (Geng et al., 2023) Open Assistant Pythia 12B* Mosaic MPT7B (MosaicML-Team, 2023) Mosaic mpt-instruct (MosaicML-Team, 2023) Mosaic mpt-chat (MosaicML-Team, 2023) Wizard 7B (Xu et al., 2023) Wizard 7B Uncensored (Xu et al., 2023) Wizard 13B Uncensored (Xu et al., 2023) GPT4-x-Vicuna-13b (Nous-Research, 2023a) Falcon 7b (Almazrouei et al., 2023) Falcon 7b instruct (Almazrouei et al., 2023) 73.4 74 74.8 73.6 68.6 73.1 83.3 77.6 79.5 83.9 81.5 68.8 56.7 73.9 74.3 65.4 73.1 68.5 63.5 67.7 81.5 76.6 81.5 82.3 62.5 60.1 76.5 67.9 74.8 74.3 77.1 78.4 77.7 78.4 81.3 73.6 70.9 74.8 75.1 74.9 74.3 75.8 77.6 79.2 79.8 78.9 80.7 80.7 77.3 75.4 77.2 79.3 76.2 77.4 79.1 76.3 76.6 64.6 77.2 76.8 78.6 71.2 67.4 77.9 78 79.3 80.4 78.2 77.2 74.2 75.5 75 80.7 78.6 63.4 63.2 63.6 63.8 66.2 72.1 75 74.9 80 80.1 80.4 67.6 71 73.9 74 66.2 73 76.2 64 67.3 46.3 70.7 73.3 74.1 53.6 41.2 72.6 68.1 76.3 77.2 74.5 69.9 68 72.1 75.2 76.3 69.8 64.7 63.6 63.8 63.5 63.5 67.8 71.3 70.1 71.9 71.3 72.5 63.9 62.2 66.1 68.8 64.1 66.9 70.1 61.1 63.8 61.8 67.3 66.7 70.9 54.8 50.1 68.8 65 68.6 67.8 67.5 66.5 65.2 69.5 65 67.3 66.7 54.9 55.4 56.6 57.7 56.4 51.1 60.9 67.9 74.2 75.7 77.6 62.9 64.6 59.8 56.6 62.2 52.5 60 61.3 63.9 49.3 53.5 57.4 61 52.4 44.9 54.3 64.2 70 72.2 69.4 56.8 53.5 57.5 58.7 71 67.9 36 34.9 35.3 35 35.7 40.4 44.2 43.4 50.9 52.1 50.7 38.7 38.5 43.3 43.9 36.6 41.4 44.6 35.2 34.8 33.3 41.2 42.7 43.5 31.1 27 41 40.4 42.2 44.6 43.3 40.5 38.7 40.4 43.9 43.3 42.7 40.2 38.4 41 38.8 40.2 40.2 43.4 42.6 46.4 46.2 45.6 41.2 40.4 43.4 42.6 38.2 42.4 42.2 37.2 38 39.4 40.8 43.6 44.4 33.4 32 42.8 43.2 42.6 43 44.2 42.6 41.6 44 43.6 44.4 41.2 text-davinci-003 88.1 83.8 83.4 75.8 83.9 63.9 51.0 58.2 57.8 58.6 58.1 58.1 60.3 65.3 65.2 68.8 70.0 69.9 60.1 58.4 62.5 62.8 58.4 61.0 63.0 56.9 58.9 53.7 61.0 63.1 65.0 51.3 46.1 62.0 61.0 64.8 65.6 64.9 61.7 59.8 62.5 63.2 65.2 62.5 75.7'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unstructured.documents.elements.ElementMetadata at 0x38ac049d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, comes the most interesting part ( utilizing the extracted data in most efficient way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's helpful to have an HTML representation of the table so that you can the information to an LLM while maintaining the table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = tables[0].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><thead><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-e</th><th>ARC-c</th><th>OBQA</th><th>Avg.</th></thead><tr><td>GPT4All-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>549</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4All-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>554</td><td>349</td><td>38.4</td><td>57.8</td></tr><tr><td>GPT4All-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>63.8</td><td>56.6</td><td>353</td><td>41</td><td>58.6</td></tr><tr><td>GPT4All-J v1.3-groovy*</td><td>73.6</td><td>743</td><td>63.8</td><td>63.5</td><td>577</td><td>35</td><td>38.8</td><td>58.1</td></tr><tr><td>GPT4All-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>357</td><td>40.2</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>72.1</td><td>67.8</td><td>511</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>833</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>442</td><td>434</td><td>65.3</td></tr><tr><td>GPT4All Falcon</td><td>77.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>43.4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>71.9</td><td>74.2</td><td>50.9</td><td>46.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>77.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>773</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>71</td><td>62.2</td><td>64.6</td><td>385</td><td>40.4</td><td>58.4</td></tr><tr><td>Alpaca 7B* (Taori et al., 2023)</td><td>73.9</td><td>772</td><td>73.9</td><td>66.1</td><td>59.8</td><td>433</td><td>434</td><td>62.5</td></tr><tr><td>Alpaca Lora 7B* (Wang, 2023)</td><td>743</td><td>79.3</td><td>74</td><td>68.8</td><td>56.6</td><td>439</td><td>42.6</td><td>62.8</td></tr><tr><td>GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B*</td><td>65.4 73.1</td><td>76.2 774</td><td>66.2 73</td><td>64.1</td><td>62.2 525</td><td>36.6 41.4</td><td>382 424</td><td>58.4 61.0</td></tr><tr><td>(Touvron et al., 2023) LLama 13B*</td><td>68.5</td><td></td><td>76.2</td><td>66.9 70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>(Touvron et al., 2023)</td><td></td><td>79.1</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>352</td><td>372</td><td>56.9</td></tr><tr><td>12B* (Biderman et al., 2023)</td><td>67.7</td><td>76.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Pythia</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Fastchat T5* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>61.8</td><td>49.3</td><td>333</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicuna* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>535</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicuia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>574</td><td>42.7</td><td>43.6</td><td>63.1</td></tr><tr><td>StableVicufia RLHF*</td><td>823</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>444</td><td>65.0</td></tr><tr><td>(Stability-Al, 2023) StableLM Tuned* (Stability-Al, 2023)</td><td>62.5</td><td>71.2</td><td>53.6</td><td>54.8</td><td>524</td><td>31.1</td><td>334</td><td>513</td></tr><tr><td>StableLM Base* (Stability-Al, 2023) Koala 13B* (Geng et al., 2023)</td><td>60.1 76.5</td><td>67.4 77.9</td><td>41.2 72.6</td><td>50.1 68.8</td><td>449 543</td><td>27 41</td><td>32 428</td><td>46.1 62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>40.4</td><td>432</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>422</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>74.3</td><td>80.4</td><td>77.2</td><td>67.8</td><td>722</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>77.1</td><td>78.2</td><td>74.5</td><td>67.5</td><td>69.4</td><td>433</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B (Xu et al., 2023)</td><td>78.4</td><td>77.2</td><td>69.9</td><td>66.5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61.7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>71.7</td><td>742</td><td>68</td><td>65.2</td><td>535</td><td>387</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al., 2023)</td><td>78.4</td><td>75.5</td><td>72.1</td><td>69.5</td><td>575</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>81.3</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>439</td><td>43.6</td><td>63.2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67.3</td><td>71</td><td>433</td><td>444</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>70.9</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr><tr><td>text-davinci-003</td><td>88.1</td><td>83.8</td><td>83.4</td><td>75.8</td><td>839</td><td>63.9</td><td>51.0</td><td>75.7</td></tr></table>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <thead>\n",
      "    <th>Model</th>\n",
      "    <th>BoolQ</th>\n",
      "    <th>PIQA</th>\n",
      "    <th>HellaSwag</th>\n",
      "    <th>WinoG.</th>\n",
      "    <th>ARC-e</th>\n",
      "    <th>ARC-c</th>\n",
      "    <th>OBQA</th>\n",
      "    <th>Avg.</th>\n",
      "  </thead>\n",
      "  <tr>\n",
      "    <td>GPT4All-J 6B v1.0*</td>\n",
      "    <td>73.4</td>\n",
      "    <td>74.8</td>\n",
      "    <td>63.4</td>\n",
      "    <td>64.7</td>\n",
      "    <td>549</td>\n",
      "    <td>36</td>\n",
      "    <td>40.2</td>\n",
      "    <td>58.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All-J v1.1-breezy*</td>\n",
      "    <td>74</td>\n",
      "    <td>75.1</td>\n",
      "    <td>63.2</td>\n",
      "    <td>63.6</td>\n",
      "    <td>554</td>\n",
      "    <td>349</td>\n",
      "    <td>38.4</td>\n",
      "    <td>57.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All-J v1.2-jazzy*</td>\n",
      "    <td>74.8</td>\n",
      "    <td>74.9</td>\n",
      "    <td>63.6</td>\n",
      "    <td>63.8</td>\n",
      "    <td>56.6</td>\n",
      "    <td>353</td>\n",
      "    <td>41</td>\n",
      "    <td>58.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All-J v1.3-groovy*</td>\n",
      "    <td>73.6</td>\n",
      "    <td>743</td>\n",
      "    <td>63.8</td>\n",
      "    <td>63.5</td>\n",
      "    <td>577</td>\n",
      "    <td>35</td>\n",
      "    <td>38.8</td>\n",
      "    <td>58.1</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All-J Lora 6B*</td>\n",
      "    <td>68.6</td>\n",
      "    <td>75.8</td>\n",
      "    <td>66.2</td>\n",
      "    <td>63.5</td>\n",
      "    <td>56.4</td>\n",
      "    <td>357</td>\n",
      "    <td>40.2</td>\n",
      "    <td>58.1</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All LLaMa Lora 7B*</td>\n",
      "    <td>73.1</td>\n",
      "    <td>77.6</td>\n",
      "    <td>72.1</td>\n",
      "    <td>67.8</td>\n",
      "    <td>511</td>\n",
      "    <td>40.4</td>\n",
      "    <td>40.2</td>\n",
      "    <td>60.3</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All 13B snoozy*</td>\n",
      "    <td>833</td>\n",
      "    <td>79.2</td>\n",
      "    <td>75</td>\n",
      "    <td>71.3</td>\n",
      "    <td>60.9</td>\n",
      "    <td>442</td>\n",
      "    <td>434</td>\n",
      "    <td>65.3</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4All Falcon</td>\n",
      "    <td>77.6</td>\n",
      "    <td>79.8</td>\n",
      "    <td>74.9</td>\n",
      "    <td>70.1</td>\n",
      "    <td>67.9</td>\n",
      "    <td>43.4</td>\n",
      "    <td>42.6</td>\n",
      "    <td>65.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Nous-Hermes (Nous-Research, 2023b)</td>\n",
      "    <td>79.5</td>\n",
      "    <td>78.9</td>\n",
      "    <td>80</td>\n",
      "    <td>71.9</td>\n",
      "    <td>74.2</td>\n",
      "    <td>50.9</td>\n",
      "    <td>46.4</td>\n",
      "    <td>68.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Nous-Hermes2 (Nous-Research, 2023c)</td>\n",
      "    <td>83.9</td>\n",
      "    <td>80.7</td>\n",
      "    <td>80.1</td>\n",
      "    <td>71.3</td>\n",
      "    <td>75.7</td>\n",
      "    <td>52.1</td>\n",
      "    <td>46.2</td>\n",
      "    <td>70.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Nous-Puffin (Nous-Research, 2023d)</td>\n",
      "    <td>815</td>\n",
      "    <td>80.7</td>\n",
      "    <td>80.4</td>\n",
      "    <td>72.5</td>\n",
      "    <td>77.6</td>\n",
      "    <td>50.7</td>\n",
      "    <td>45.6</td>\n",
      "    <td>69.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Dolly 6B* (Conover et al., 2023a)</td>\n",
      "    <td>68.8</td>\n",
      "    <td>773</td>\n",
      "    <td>67.6</td>\n",
      "    <td>63.9</td>\n",
      "    <td>62.9</td>\n",
      "    <td>38.7</td>\n",
      "    <td>412</td>\n",
      "    <td>60.1</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Dolly 12B* (Conover et al., 2023b)</td>\n",
      "    <td>56.7</td>\n",
      "    <td>75.4</td>\n",
      "    <td>71</td>\n",
      "    <td>62.2</td>\n",
      "    <td>64.6</td>\n",
      "    <td>385</td>\n",
      "    <td>40.4</td>\n",
      "    <td>58.4</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Alpaca 7B* (Taori et al., 2023)</td>\n",
      "    <td>73.9</td>\n",
      "    <td>772</td>\n",
      "    <td>73.9</td>\n",
      "    <td>66.1</td>\n",
      "    <td>59.8</td>\n",
      "    <td>433</td>\n",
      "    <td>434</td>\n",
      "    <td>62.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Alpaca Lora 7B* (Wang, 2023)</td>\n",
      "    <td>743</td>\n",
      "    <td>79.3</td>\n",
      "    <td>74</td>\n",
      "    <td>68.8</td>\n",
      "    <td>56.6</td>\n",
      "    <td>439</td>\n",
      "    <td>42.6</td>\n",
      "    <td>62.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B*</td>\n",
      "    <td>65.4 73.1</td>\n",
      "    <td>76.2 774</td>\n",
      "    <td>66.2 73</td>\n",
      "    <td>64.1</td>\n",
      "    <td>62.2 525</td>\n",
      "    <td>36.6 41.4</td>\n",
      "    <td>382 424</td>\n",
      "    <td>58.4 61.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>(Touvron et al., 2023) LLama 13B*</td>\n",
      "    <td>68.5</td>\n",
      "    <td/>\n",
      "    <td>76.2</td>\n",
      "    <td>66.9 70.1</td>\n",
      "    <td>60</td>\n",
      "    <td>44.6</td>\n",
      "    <td>422</td>\n",
      "    <td>63.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>(Touvron et al., 2023)</td>\n",
      "    <td/>\n",
      "    <td>79.1</td>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Pythia 6.7B* (Biderman et al., 2023)</td>\n",
      "    <td>63.5</td>\n",
      "    <td>76.3</td>\n",
      "    <td>64</td>\n",
      "    <td>61.1</td>\n",
      "    <td>61.3</td>\n",
      "    <td>352</td>\n",
      "    <td>372</td>\n",
      "    <td>56.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>12B* (Biderman et al., 2023)</td>\n",
      "    <td>67.7</td>\n",
      "    <td>76.6</td>\n",
      "    <td>67.3</td>\n",
      "    <td>63.8</td>\n",
      "    <td>63.9</td>\n",
      "    <td>34.8</td>\n",
      "    <td>38</td>\n",
      "    <td>58.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Pythia</td>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "    <td/>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Fastchat T5* (Zheng et al., 2023)</td>\n",
      "    <td>815</td>\n",
      "    <td>64.6</td>\n",
      "    <td>46.3</td>\n",
      "    <td>61.8</td>\n",
      "    <td>49.3</td>\n",
      "    <td>333</td>\n",
      "    <td>39.4</td>\n",
      "    <td>53.7</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Fastchat Vicuna* 7B (Zheng et al., 2023)</td>\n",
      "    <td>76.6</td>\n",
      "    <td>77.2</td>\n",
      "    <td>70.7</td>\n",
      "    <td>67.3</td>\n",
      "    <td>535</td>\n",
      "    <td>41.2</td>\n",
      "    <td>40.8</td>\n",
      "    <td>61.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Fastchat Vicuia 13B* (Zheng et al., 2023)</td>\n",
      "    <td>815</td>\n",
      "    <td>76.8</td>\n",
      "    <td>73.3</td>\n",
      "    <td>66.7</td>\n",
      "    <td>574</td>\n",
      "    <td>42.7</td>\n",
      "    <td>43.6</td>\n",
      "    <td>63.1</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>StableVicufia RLHF*</td>\n",
      "    <td>823</td>\n",
      "    <td>78.6</td>\n",
      "    <td>74.1</td>\n",
      "    <td>70.9</td>\n",
      "    <td>61</td>\n",
      "    <td>43.5</td>\n",
      "    <td>444</td>\n",
      "    <td>65.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>(Stability-Al, 2023) StableLM Tuned* (Stability-Al, 2023)</td>\n",
      "    <td>62.5</td>\n",
      "    <td>71.2</td>\n",
      "    <td>53.6</td>\n",
      "    <td>54.8</td>\n",
      "    <td>524</td>\n",
      "    <td>31.1</td>\n",
      "    <td>334</td>\n",
      "    <td>513</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>StableLM Base* (Stability-Al, 2023) Koala 13B* (Geng et al., 2023)</td>\n",
      "    <td>60.1 76.5</td>\n",
      "    <td>67.4 77.9</td>\n",
      "    <td>41.2 72.6</td>\n",
      "    <td>50.1 68.8</td>\n",
      "    <td>449 543</td>\n",
      "    <td>27 41</td>\n",
      "    <td>32 428</td>\n",
      "    <td>46.1 62.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Open Assistant Pythia 12B*</td>\n",
      "    <td>67.9</td>\n",
      "    <td>78</td>\n",
      "    <td>68.1</td>\n",
      "    <td>65</td>\n",
      "    <td>64.2</td>\n",
      "    <td>40.4</td>\n",
      "    <td>432</td>\n",
      "    <td>61.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mosaic MPT7B (MosaicML-Team, 2023)</td>\n",
      "    <td>74.8</td>\n",
      "    <td>79.3</td>\n",
      "    <td>76.3</td>\n",
      "    <td>68.6</td>\n",
      "    <td>70</td>\n",
      "    <td>422</td>\n",
      "    <td>42.6</td>\n",
      "    <td>64.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td>\n",
      "    <td>74.3</td>\n",
      "    <td>80.4</td>\n",
      "    <td>77.2</td>\n",
      "    <td>67.8</td>\n",
      "    <td>722</td>\n",
      "    <td>44.6</td>\n",
      "    <td>43</td>\n",
      "    <td>65.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mosaic mpt-chat (MosaicML-Team, 2023)</td>\n",
      "    <td>77.1</td>\n",
      "    <td>78.2</td>\n",
      "    <td>74.5</td>\n",
      "    <td>67.5</td>\n",
      "    <td>69.4</td>\n",
      "    <td>433</td>\n",
      "    <td>44.2</td>\n",
      "    <td>64.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Wizard 7B (Xu et al., 2023)</td>\n",
      "    <td>78.4</td>\n",
      "    <td>77.2</td>\n",
      "    <td>69.9</td>\n",
      "    <td>66.5</td>\n",
      "    <td>56.8</td>\n",
      "    <td>40.5</td>\n",
      "    <td>42.6</td>\n",
      "    <td>61.7</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Wizard 7B Uncensored (Xu et al., 2023)</td>\n",
      "    <td>71.7</td>\n",
      "    <td>742</td>\n",
      "    <td>68</td>\n",
      "    <td>65.2</td>\n",
      "    <td>535</td>\n",
      "    <td>387</td>\n",
      "    <td>41.6</td>\n",
      "    <td>59.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Wizard 13B Uncensored (Xu et al., 2023)</td>\n",
      "    <td>78.4</td>\n",
      "    <td>75.5</td>\n",
      "    <td>72.1</td>\n",
      "    <td>69.5</td>\n",
      "    <td>575</td>\n",
      "    <td>40.4</td>\n",
      "    <td>44</td>\n",
      "    <td>62.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td>\n",
      "    <td>81.3</td>\n",
      "    <td>75</td>\n",
      "    <td>75.2</td>\n",
      "    <td>65</td>\n",
      "    <td>58.7</td>\n",
      "    <td>439</td>\n",
      "    <td>43.6</td>\n",
      "    <td>63.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Falcon 7b (Almazrouei et al., 2023)</td>\n",
      "    <td>73.6</td>\n",
      "    <td>80.7</td>\n",
      "    <td>76.3</td>\n",
      "    <td>67.3</td>\n",
      "    <td>71</td>\n",
      "    <td>433</td>\n",
      "    <td>444</td>\n",
      "    <td>65.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Falcon 7b instruct (Almazrouei et al., 2023)</td>\n",
      "    <td>70.9</td>\n",
      "    <td>78.6</td>\n",
      "    <td>69.8</td>\n",
      "    <td>66.7</td>\n",
      "    <td>67.9</td>\n",
      "    <td>42.7</td>\n",
      "    <td>412</td>\n",
      "    <td>62.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>text-davinci-003</td>\n",
      "    <td>88.1</td>\n",
      "    <td>83.8</td>\n",
      "    <td>83.4</td>\n",
      "    <td>75.8</td>\n",
      "    <td>839</td>\n",
      "    <td>63.9</td>\n",
      "    <td>51.0</td>\n",
      "    <td>75.7</td>\n",
      "  </tr>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view what the HTML in the metadata field looks like\n",
    "\n",
    "from io import StringIO \n",
    "from lxml import etree\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "file_obj = StringIO(table_html)\n",
    "tree = etree.parse(file_obj, parser)\n",
    "print(etree.tostring(tree, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-e</th><th>ARC-c</th><th>OBQA</th><th>Avg.</th></thead><tr><td>GPT4All-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>549</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4All-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>554</td><td>349</td><td>38.4</td><td>57.8</td></tr><tr><td>GPT4All-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>63.8</td><td>56.6</td><td>353</td><td>41</td><td>58.6</td></tr><tr><td>GPT4All-J v1.3-groovy*</td><td>73.6</td><td>743</td><td>63.8</td><td>63.5</td><td>577</td><td>35</td><td>38.8</td><td>58.1</td></tr><tr><td>GPT4All-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>357</td><td>40.2</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>72.1</td><td>67.8</td><td>511</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>833</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>442</td><td>434</td><td>65.3</td></tr><tr><td>GPT4All Falcon</td><td>77.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>43.4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>71.9</td><td>74.2</td><td>50.9</td><td>46.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>77.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>773</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>71</td><td>62.2</td><td>64.6</td><td>385</td><td>40.4</td><td>58.4</td></tr><tr><td>Alpaca 7B* (Taori et al., 2023)</td><td>73.9</td><td>772</td><td>73.9</td><td>66.1</td><td>59.8</td><td>433</td><td>434</td><td>62.5</td></tr><tr><td>Alpaca Lora 7B* (Wang, 2023)</td><td>743</td><td>79.3</td><td>74</td><td>68.8</td><td>56.6</td><td>439</td><td>42.6</td><td>62.8</td></tr><tr><td>GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B*</td><td>65.4 73.1</td><td>76.2 774</td><td>66.2 73</td><td>64.1</td><td>62.2 525</td><td>36.6 41.4</td><td>382 424</td><td>58.4 61.0</td></tr><tr><td>(Touvron et al., 2023) LLama 13B*</td><td>68.5</td><td></td><td>76.2</td><td>66.9 70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>(Touvron et al., 2023)</td><td></td><td>79.1</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>352</td><td>372</td><td>56.9</td></tr><tr><td>12B* (Biderman et al., 2023)</td><td>67.7</td><td>76.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Pythia</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Fastchat T5* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>61.8</td><td>49.3</td><td>333</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicuna* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>535</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicuia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>574</td><td>42.7</td><td>43.6</td><td>63.1</td></tr><tr><td>StableVicufia RLHF*</td><td>823</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>444</td><td>65.0</td></tr><tr><td>(Stability-Al, 2023) StableLM Tuned* (Stability-Al, 2023)</td><td>62.5</td><td>71.2</td><td>53.6</td><td>54.8</td><td>524</td><td>31.1</td><td>334</td><td>513</td></tr><tr><td>StableLM Base* (Stability-Al, 2023) Koala 13B* (Geng et al., 2023)</td><td>60.1 76.5</td><td>67.4 77.9</td><td>41.2 72.6</td><td>50.1 68.8</td><td>449 543</td><td>27 41</td><td>32 428</td><td>46.1 62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>40.4</td><td>432</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>422</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>74.3</td><td>80.4</td><td>77.2</td><td>67.8</td><td>722</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>77.1</td><td>78.2</td><td>74.5</td><td>67.5</td><td>69.4</td><td>433</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B (Xu et al., 2023)</td><td>78.4</td><td>77.2</td><td>69.9</td><td>66.5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61.7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>71.7</td><td>742</td><td>68</td><td>65.2</td><td>535</td><td>387</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al., 2023)</td><td>78.4</td><td>75.5</td><td>72.1</td><td>69.5</td><td>575</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>81.3</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>439</td><td>43.6</td><td>63.2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67.3</td><td>71</td><td>433</td><td>444</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>70.9</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr><tr><td>text-davinci-003</td><td>88.1</td><td>83.8</td><td>83.4</td><td>75.8</td><td>839</td><td>63.9</td><td>51.0</td><td>75.7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's display this table\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(table_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, lets plugin in LangChain to summarize these tables using `Llama3` via `Ollama`\n",
    "#### [Ollama Playlist](https://www.youtube.com/playlist?list=PLz-qytj7eIWX-bpcRtvkixvo9fuejVr8y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain_core in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (0.1.50)\n",
      "Requirement already satisfied: langchain_community in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (0.0.36)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (0.6.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (0.1.53)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.1.17 langchain-text-splitters-0.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_core langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mChatOllama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Union[BaseCache, bool, None]'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Callbacks'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcustom_get_token_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbase_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://localhost:11434'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'llama2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmirostat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmirostat_eta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmirostat_tau\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_ctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_gpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_thread\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_predict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrepeat_last_n\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrepeat_penalty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtfs_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtop_p\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msystem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtemplate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallback_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mChatOllama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseChatModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_OllamaCommon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Ollama locally runs large language models.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    To use, follow the instructions at https://ollama.ai/.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example:\u001b[0m\n",
      "\u001b[0;34m        .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            from langchain_community.chat_models import ChatOllama\u001b[0m\n",
      "\u001b[0;34m            ollama = ChatOllama(model=\"llama2\")\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_llm_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return type of chat model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"ollama-chat\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mis_lc_serializable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return whether this model can be serialized by Langchain.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.0.3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_convert_messages_to_ollama_messages\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_format_message_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n\\n{message.role.capitalize()}: {message.content}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mfirst_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mcontent_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mmessage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[INST] {first_content['text']} [/INST]\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0mcontent_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mmessage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmessage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[INST] {message.content} [/INST]\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{message.content}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"<<SYS>> {message.content} <</SYS>>\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got unknown type {message}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmessage_text\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_format_messages_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_message_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_convert_messages_to_ollama_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mollama_messages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Received unsupported message type for Ollama.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mcontent_part\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mcontent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\n{content_part['text']}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32melif\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0mimage_url_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;31m# Support data:image/jpeg;base64,<image> format\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;31m# and base64 strings\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_components\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_components\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_components\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                \u001b[0;34m\"Only string image_url \"\u001b[0m \u001b[0;34m\"content parts are supported.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"Unsupported message content type. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"Must either have type 'text' or type 'image_url' \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"with a string 'image_url' field.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mollama_messages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mollama_messages\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_create_chat_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_messages_to_ollama_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{self.base_url}/api/chat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_acreate_chat_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAsyncIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_messages_to_ollama_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acreate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{self.base_url}/api/chat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_chat_stream_with_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfinal_chunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chat_stream_response_to_chat_generation_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data received from Ollama stream.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_achat_stream_with_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAsyncCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfinal_chunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acreate_chat_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chat_stream_response_to_chat_generation_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data received from Ollama stream.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Call out to Ollama's generate endpoint.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            messages: The list of base messages to pass into the model.\u001b[0m\n",
      "\u001b[0;34m            stop: Optional list of stop words to use when generating.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            Chat generations from the model\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Example:\u001b[0m\n",
      "\u001b[0;34m            .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                response = ollama([\u001b[0m\n",
      "\u001b[0;34m                    HumanMessage(content=\"Tell me about the history of AI\")\u001b[0m\n",
      "\u001b[0;34m                ])\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chat_stream_with_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mchat_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mgeneration_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchat_generation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_agenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAsyncCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Call out to Ollama's generate endpoint.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            messages: The list of base messages to pass into the model.\u001b[0m\n",
      "\u001b[0;34m            stop: Optional list of stop words to use when generating.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            Chat generations from the model\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Example:\u001b[0m\n",
      "\u001b[0;34m            .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                response = ollama([\u001b[0m\n",
      "\u001b[0;34m                    HumanMessage(content=\"Tell me about the history of AI\")\u001b[0m\n",
      "\u001b[0;34m                ])\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_achat_stream_with_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mchat_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mgeneration_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchat_generation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chat_stream_response_to_chat_generation_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0mchunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mOllamaEndpointNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_astream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAsyncCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAsyncIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acreate_chat_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chat_stream_response_to_chat_generation_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.0.3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_legacy_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_messages_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_generate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stream_response_to_chat_generation_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py\n",
      "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "ChatOllama??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "output = chain.invoke([Document(page_content=table_html)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='<table><thead><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-e</th><th>ARC-c</th><th>OBQA</th><th>Avg.</th></thead><tr><td>GPT4All-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>549</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4All-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>554</td><td>349</td><td>38.4</td><td>57.8</td></tr><tr><td>GPT4All-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>63.8</td><td>56.6</td><td>353</td><td>41</td><td>58.6</td></tr><tr><td>GPT4All-J v1.3-groovy*</td><td>73.6</td><td>743</td><td>63.8</td><td>63.5</td><td>577</td><td>35</td><td>38.8</td><td>58.1</td></tr><tr><td>GPT4All-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>357</td><td>40.2</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>72.1</td><td>67.8</td><td>511</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>833</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>442</td><td>434</td><td>65.3</td></tr><tr><td>GPT4All Falcon</td><td>77.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>43.4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>71.9</td><td>74.2</td><td>50.9</td><td>46.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>77.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>773</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>71</td><td>62.2</td><td>64.6</td><td>385</td><td>40.4</td><td>58.4</td></tr><tr><td>Alpaca 7B* (Taori et al., 2023)</td><td>73.9</td><td>772</td><td>73.9</td><td>66.1</td><td>59.8</td><td>433</td><td>434</td><td>62.5</td></tr><tr><td>Alpaca Lora 7B* (Wang, 2023)</td><td>743</td><td>79.3</td><td>74</td><td>68.8</td><td>56.6</td><td>439</td><td>42.6</td><td>62.8</td></tr><tr><td>GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B*</td><td>65.4 73.1</td><td>76.2 774</td><td>66.2 73</td><td>64.1</td><td>62.2 525</td><td>36.6 41.4</td><td>382 424</td><td>58.4 61.0</td></tr><tr><td>(Touvron et al., 2023) LLama 13B*</td><td>68.5</td><td></td><td>76.2</td><td>66.9 70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>(Touvron et al., 2023)</td><td></td><td>79.1</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>352</td><td>372</td><td>56.9</td></tr><tr><td>12B* (Biderman et al., 2023)</td><td>67.7</td><td>76.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Pythia</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Fastchat T5* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>61.8</td><td>49.3</td><td>333</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicuna* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>535</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicuia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>574</td><td>42.7</td><td>43.6</td><td>63.1</td></tr><tr><td>StableVicufia RLHF*</td><td>823</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>444</td><td>65.0</td></tr><tr><td>(Stability-Al, 2023) StableLM Tuned* (Stability-Al, 2023)</td><td>62.5</td><td>71.2</td><td>53.6</td><td>54.8</td><td>524</td><td>31.1</td><td>334</td><td>513</td></tr><tr><td>StableLM Base* (Stability-Al, 2023) Koala 13B* (Geng et al., 2023)</td><td>60.1 76.5</td><td>67.4 77.9</td><td>41.2 72.6</td><td>50.1 68.8</td><td>449 543</td><td>27 41</td><td>32 428</td><td>46.1 62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>40.4</td><td>432</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>422</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>74.3</td><td>80.4</td><td>77.2</td><td>67.8</td><td>722</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>77.1</td><td>78.2</td><td>74.5</td><td>67.5</td><td>69.4</td><td>433</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B (Xu et al., 2023)</td><td>78.4</td><td>77.2</td><td>69.9</td><td>66.5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61.7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>71.7</td><td>742</td><td>68</td><td>65.2</td><td>535</td><td>387</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al., 2023)</td><td>78.4</td><td>75.5</td><td>72.1</td><td>69.5</td><td>575</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>81.3</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>439</td><td>43.6</td><td>63.2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67.3</td><td>71</td><td>433</td><td>444</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>70.9</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr><tr><td>text-davinci-003</td><td>88.1</td><td>83.8</td><td>83.4</td><td>75.8</td><td>839</td><td>63.9</td><td>51.0</td><td>75.7</td></tr></table>')],\n",
       " 'output_text': \"It seems like you're sharing a table comparing the performance of various AI models on the SuperGLUE benchmark, with a focus on the StableLM model and its variants.\\n\\nIf I were to summarize this information in a concise manner:\\n\\n* The StableLM model, when tuned for stability (Stability-Al, 2023), achieves an overall score of 78.6, outperforming some other models.\\n* The Koala 13B model achieves similar scores to the StableLM model, but with slightly better results on certain tasks.\\n* Mosaic models generally perform well, especially the MPT7B and mpt-chat variants.\\n* Wizard models also show promising results, although their performance may be affected by censorship.\\n* GPT-4 and Falcon 7b models demonstrate strong performance as well.\\n\\nLet me know if you'd like me to help with any further analysis or insights!\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like you're sharing a table comparing the performance of various AI models on the SuperGLUE benchmark, with a focus on the StableLM model and its variants.\n",
      "\n",
      "If I were to summarize this information in a concise manner:\n",
      "\n",
      "* The StableLM model, when tuned for stability (Stability-Al, 2023), achieves an overall score of 78.6, outperforming some other models.\n",
      "* The Koala 13B model achieves similar scores to the StableLM model, but with slightly better results on certain tasks.\n",
      "* Mosaic models generally perform well, especially the MPT7B and mpt-chat variants.\n",
      "* Wizard models also show promising results, although their performance may be affected by censorship.\n",
      "* GPT-4 and Falcon 7b models demonstrate strong performance as well.\n",
      "\n",
      "Let me know if you'd like me to help with any further analysis or insights!\n"
     ]
    }
   ],
   "source": [
    "print(output['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sudarshan/Documents/yt-code/youtube-stuffs/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert HTML table to pandas DataFrame\n",
    "dfs = pd.read_html(table_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                Model      BoolQ       PIQA  \\\n",
       " 0                                  GPT4All-J 6B v1.0*       73.4       74.8   \n",
       " 1                              GPT4All-J v1.1-breezy*         74       75.1   \n",
       " 2                               GPT4All-J v1.2-jazzy*       74.8       74.9   \n",
       " 3                              GPT4All-J v1.3-groovy*       73.6        743   \n",
       " 4                                  GPT4All-J Lora 6B*       68.6       75.8   \n",
       " 5                              GPT4All LLaMa Lora 7B*       73.1       77.6   \n",
       " 6                                 GPT4All 13B snoozy*        833       79.2   \n",
       " 7                                      GPT4All Falcon       77.6       79.8   \n",
       " 8                  Nous-Hermes (Nous-Research, 2023b)       79.5       78.9   \n",
       " 9                 Nous-Hermes2 (Nous-Research, 2023c)       83.9       80.7   \n",
       " 10                 Nous-Puffin (Nous-Research, 2023d)        815       80.7   \n",
       " 11                  Dolly 6B* (Conover et al., 2023a)       68.8        773   \n",
       " 12                 Dolly 12B* (Conover et al., 2023b)       56.7       75.4   \n",
       " 13                    Alpaca 7B* (Taori et al., 2023)       73.9        772   \n",
       " 14                       Alpaca Lora 7B* (Wang, 2023)        743       79.3   \n",
       " 15  GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama...  65.4 73.1   76.2 774   \n",
       " 16                  (Touvron et al., 2023) LLama 13B*       68.5        NaN   \n",
       " 17                             (Touvron et al., 2023)        NaN       79.1   \n",
       " 18               Pythia 6.7B* (Biderman et al., 2023)       63.5       76.3   \n",
       " 19                       12B* (Biderman et al., 2023)       67.7       76.6   \n",
       " 20                                             Pythia        NaN        NaN   \n",
       " 21                  Fastchat T5* (Zheng et al., 2023)        815       64.6   \n",
       " 22           Fastchat Vicuna* 7B (Zheng et al., 2023)       76.6       77.2   \n",
       " 23          Fastchat Vicuia 13B* (Zheng et al., 2023)        815       76.8   \n",
       " 24                                StableVicufia RLHF*        823       78.6   \n",
       " 25  (Stability-Al, 2023) StableLM Tuned* (Stabilit...       62.5       71.2   \n",
       " 26  StableLM Base* (Stability-Al, 2023) Koala 13B*...  60.1 76.5  67.4 77.9   \n",
       " 27                         Open Assistant Pythia 12B*       67.9         78   \n",
       " 28                 Mosaic MPT7B (MosaicML-Team, 2023)       74.8       79.3   \n",
       " 29          Mosaic mpt-instruct (MosaicML-Team, 2023)       74.3       80.4   \n",
       " 30              Mosaic mpt-chat (MosaicML-Team, 2023)       77.1       78.2   \n",
       " 31                        Wizard 7B (Xu et al., 2023)       78.4       77.2   \n",
       " 32             Wizard 7B Uncensored (Xu et al., 2023)       71.7        742   \n",
       " 33            Wizard 13B Uncensored (Xu et al., 2023)       78.4       75.5   \n",
       " 34           GPT4-x-Vicuna-13b (Nous-Research, 2023a)       81.3         75   \n",
       " 35                Falcon 7b (Almazrouei et al., 2023)       73.6       80.7   \n",
       " 36       Falcon 7b instruct (Almazrouei et al., 2023)       70.9       78.6   \n",
       " 37                                   text-davinci-003       88.1       83.8   \n",
       " \n",
       "     HellaSwag     WinoG.     ARC-e      ARC-c     OBQA       Avg.  \n",
       " 0        63.4       64.7       549         36     40.2       58.2  \n",
       " 1        63.2       63.6       554        349     38.4       57.8  \n",
       " 2        63.6       63.8      56.6        353       41       58.6  \n",
       " 3        63.8       63.5       577         35     38.8       58.1  \n",
       " 4        66.2       63.5      56.4        357     40.2       58.1  \n",
       " 5        72.1       67.8       511       40.4     40.2       60.3  \n",
       " 6          75       71.3      60.9        442      434       65.3  \n",
       " 7        74.9       70.1      67.9       43.4     42.6       65.2  \n",
       " 8          80       71.9      74.2       50.9     46.4       68.8  \n",
       " 9        80.1       71.3      75.7       52.1     46.2       70.0  \n",
       " 10       80.4       72.5      77.6       50.7     45.6       69.9  \n",
       " 11       67.6       63.9      62.9       38.7      412       60.1  \n",
       " 12         71       62.2      64.6        385     40.4       58.4  \n",
       " 13       73.9       66.1      59.8        433      434       62.5  \n",
       " 14         74       68.8      56.6        439     42.6       62.8  \n",
       " 15    66.2 73       64.1  62.2 525  36.6 41.4  382 424  58.4 61.0  \n",
       " 16       76.2  66.9 70.1        60       44.6      422       63.0  \n",
       " 17        NaN        NaN       NaN        NaN      NaN        NaN  \n",
       " 18         64       61.1      61.3        352      372       56.9  \n",
       " 19       67.3       63.8      63.9       34.8       38       58.9  \n",
       " 20        NaN        NaN       NaN        NaN      NaN        NaN  \n",
       " 21       46.3       61.8      49.3        333     39.4       53.7  \n",
       " 22       70.7       67.3       535       41.2     40.8       61.0  \n",
       " 23       73.3       66.7       574       42.7     43.6       63.1  \n",
       " 24       74.1       70.9        61       43.5      444       65.0  \n",
       " 25       53.6       54.8       524       31.1      334        513  \n",
       " 26  41.2 72.6  50.1 68.8   449 543      27 41   32 428  46.1 62.0  \n",
       " 27       68.1         65      64.2       40.4      432       61.0  \n",
       " 28       76.3       68.6        70        422     42.6       64.8  \n",
       " 29       77.2       67.8       722       44.6       43       65.6  \n",
       " 30       74.5       67.5      69.4        433     44.2       64.9  \n",
       " 31       69.9       66.5      56.8       40.5     42.6       61.7  \n",
       " 32         68       65.2       535        387     41.6       59.8  \n",
       " 33       72.1       69.5       575       40.4       44       62.5  \n",
       " 34       75.2         65      58.7        439     43.6       63.2  \n",
       " 35       76.3       67.3        71        433      444       65.2  \n",
       " 36       69.8       66.7      67.9       42.7      412       62.5  \n",
       " 37       83.4       75.8       839       63.9     51.0       75.7  ]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Model      BoolQ       PIQA  \\\n",
      "0                                  GPT4All-J 6B v1.0*       73.4       74.8   \n",
      "1                              GPT4All-J v1.1-breezy*         74       75.1   \n",
      "2                               GPT4All-J v1.2-jazzy*       74.8       74.9   \n",
      "3                              GPT4All-J v1.3-groovy*       73.6        743   \n",
      "4                                  GPT4All-J Lora 6B*       68.6       75.8   \n",
      "5                              GPT4All LLaMa Lora 7B*       73.1       77.6   \n",
      "6                                 GPT4All 13B snoozy*        833       79.2   \n",
      "7                                      GPT4All Falcon       77.6       79.8   \n",
      "8                  Nous-Hermes (Nous-Research, 2023b)       79.5       78.9   \n",
      "9                 Nous-Hermes2 (Nous-Research, 2023c)       83.9       80.7   \n",
      "10                 Nous-Puffin (Nous-Research, 2023d)        815       80.7   \n",
      "11                  Dolly 6B* (Conover et al., 2023a)       68.8        773   \n",
      "12                 Dolly 12B* (Conover et al., 2023b)       56.7       75.4   \n",
      "13                    Alpaca 7B* (Taori et al., 2023)       73.9        772   \n",
      "14                       Alpaca Lora 7B* (Wang, 2023)        743       79.3   \n",
      "15  GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama...  65.4 73.1   76.2 774   \n",
      "16                  (Touvron et al., 2023) LLama 13B*       68.5        NaN   \n",
      "17                             (Touvron et al., 2023)        NaN       79.1   \n",
      "18               Pythia 6.7B* (Biderman et al., 2023)       63.5       76.3   \n",
      "19                       12B* (Biderman et al., 2023)       67.7       76.6   \n",
      "20                                             Pythia        NaN        NaN   \n",
      "21                  Fastchat T5* (Zheng et al., 2023)        815       64.6   \n",
      "22           Fastchat Vicuna* 7B (Zheng et al., 2023)       76.6       77.2   \n",
      "23          Fastchat Vicuia 13B* (Zheng et al., 2023)        815       76.8   \n",
      "24                                StableVicufia RLHF*        823       78.6   \n",
      "25  (Stability-Al, 2023) StableLM Tuned* (Stabilit...       62.5       71.2   \n",
      "26  StableLM Base* (Stability-Al, 2023) Koala 13B*...  60.1 76.5  67.4 77.9   \n",
      "27                         Open Assistant Pythia 12B*       67.9         78   \n",
      "28                 Mosaic MPT7B (MosaicML-Team, 2023)       74.8       79.3   \n",
      "29          Mosaic mpt-instruct (MosaicML-Team, 2023)       74.3       80.4   \n",
      "30              Mosaic mpt-chat (MosaicML-Team, 2023)       77.1       78.2   \n",
      "31                        Wizard 7B (Xu et al., 2023)       78.4       77.2   \n",
      "32             Wizard 7B Uncensored (Xu et al., 2023)       71.7        742   \n",
      "33            Wizard 13B Uncensored (Xu et al., 2023)       78.4       75.5   \n",
      "34           GPT4-x-Vicuna-13b (Nous-Research, 2023a)       81.3         75   \n",
      "35                Falcon 7b (Almazrouei et al., 2023)       73.6       80.7   \n",
      "36       Falcon 7b instruct (Almazrouei et al., 2023)       70.9       78.6   \n",
      "37                                   text-davinci-003       88.1       83.8   \n",
      "\n",
      "    HellaSwag     WinoG.     ARC-e      ARC-c     OBQA       Avg.  \n",
      "0        63.4       64.7       549         36     40.2       58.2  \n",
      "1        63.2       63.6       554        349     38.4       57.8  \n",
      "2        63.6       63.8      56.6        353       41       58.6  \n",
      "3        63.8       63.5       577         35     38.8       58.1  \n",
      "4        66.2       63.5      56.4        357     40.2       58.1  \n",
      "5        72.1       67.8       511       40.4     40.2       60.3  \n",
      "6          75       71.3      60.9        442      434       65.3  \n",
      "7        74.9       70.1      67.9       43.4     42.6       65.2  \n",
      "8          80       71.9      74.2       50.9     46.4       68.8  \n",
      "9        80.1       71.3      75.7       52.1     46.2       70.0  \n",
      "10       80.4       72.5      77.6       50.7     45.6       69.9  \n",
      "11       67.6       63.9      62.9       38.7      412       60.1  \n",
      "12         71       62.2      64.6        385     40.4       58.4  \n",
      "13       73.9       66.1      59.8        433      434       62.5  \n",
      "14         74       68.8      56.6        439     42.6       62.8  \n",
      "15    66.2 73       64.1  62.2 525  36.6 41.4  382 424  58.4 61.0  \n",
      "16       76.2  66.9 70.1        60       44.6      422       63.0  \n",
      "17        NaN        NaN       NaN        NaN      NaN        NaN  \n",
      "18         64       61.1      61.3        352      372       56.9  \n",
      "19       67.3       63.8      63.9       34.8       38       58.9  \n",
      "20        NaN        NaN       NaN        NaN      NaN        NaN  \n",
      "21       46.3       61.8      49.3        333     39.4       53.7  \n",
      "22       70.7       67.3       535       41.2     40.8       61.0  \n",
      "23       73.3       66.7       574       42.7     43.6       63.1  \n",
      "24       74.1       70.9        61       43.5      444       65.0  \n",
      "25       53.6       54.8       524       31.1      334        513  \n",
      "26  41.2 72.6  50.1 68.8   449 543      27 41   32 428  46.1 62.0  \n",
      "27       68.1         65      64.2       40.4      432       61.0  \n",
      "28       76.3       68.6        70        422     42.6       64.8  \n",
      "29       77.2       67.8       722       44.6       43       65.6  \n",
      "30       74.5       67.5      69.4        433     44.2       64.9  \n",
      "31       69.9       66.5      56.8       40.5     42.6       61.7  \n",
      "32         68       65.2       535        387     41.6       59.8  \n",
      "33       72.1       69.5       575       40.4       44       62.5  \n",
      "34       75.2         65      58.7        439     43.6       63.2  \n",
      "35       76.3       67.3        71        433      444       65.2  \n",
      "36       69.8       66.7      67.9       42.7      412       62.5  \n",
      "37       83.4       75.8       839       63.9     51.0       75.7  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming there's only one table, get the DataFrame\n",
    "df = dfs[0]\n",
    "\n",
    "# Now you have the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 9)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>PIQA</th>\n",
       "      <th>HellaSwag</th>\n",
       "      <th>WinoG.</th>\n",
       "      <th>ARC-e</th>\n",
       "      <th>ARC-c</th>\n",
       "      <th>OBQA</th>\n",
       "      <th>Avg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT4All-J 6B v1.0*</td>\n",
       "      <td>73.4</td>\n",
       "      <td>74.8</td>\n",
       "      <td>63.4</td>\n",
       "      <td>64.7</td>\n",
       "      <td>549</td>\n",
       "      <td>36</td>\n",
       "      <td>40.2</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT4All-J v1.1-breezy*</td>\n",
       "      <td>74</td>\n",
       "      <td>75.1</td>\n",
       "      <td>63.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>554</td>\n",
       "      <td>349</td>\n",
       "      <td>38.4</td>\n",
       "      <td>57.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT4All-J v1.2-jazzy*</td>\n",
       "      <td>74.8</td>\n",
       "      <td>74.9</td>\n",
       "      <td>63.6</td>\n",
       "      <td>63.8</td>\n",
       "      <td>56.6</td>\n",
       "      <td>353</td>\n",
       "      <td>41</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT4All-J v1.3-groovy*</td>\n",
       "      <td>73.6</td>\n",
       "      <td>743</td>\n",
       "      <td>63.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>577</td>\n",
       "      <td>35</td>\n",
       "      <td>38.8</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT4All-J Lora 6B*</td>\n",
       "      <td>68.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>66.2</td>\n",
       "      <td>63.5</td>\n",
       "      <td>56.4</td>\n",
       "      <td>357</td>\n",
       "      <td>40.2</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model BoolQ  PIQA HellaSwag WinoG. ARC-e ARC-c  OBQA  Avg.\n",
       "0      GPT4All-J 6B v1.0*  73.4  74.8      63.4   64.7   549    36  40.2  58.2\n",
       "1  GPT4All-J v1.1-breezy*    74  75.1      63.2   63.6   554   349  38.4  57.8\n",
       "2   GPT4All-J v1.2-jazzy*  74.8  74.9      63.6   63.8  56.6   353    41  58.6\n",
       "3  GPT4All-J v1.3-groovy*  73.6   743      63.8   63.5   577    35  38.8  58.1\n",
       "4      GPT4All-J Lora 6B*  68.6  75.8      66.2   63.5  56.4   357  40.2  58.1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
