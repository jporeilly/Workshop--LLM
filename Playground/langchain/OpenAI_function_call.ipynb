{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhhFi5GiAMVehYFm2qziFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshan-koirala/youtube-stuffs/blob/main/langchain/OpenAI_function_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Function Call + LangChain Example\n",
        "\n",
        "## [Youtube video covering this notebook](https://youtu.be/Sn9z6ey5zo4)\n",
        "- Example 1 (Replicate the openai example\n",
        "- Example 2 (Sum of two numbers) Step by Step breakdown.\n",
        "- Example 3 (Web surfing (kinda chatgpt plugin))\n",
        "- More examples link"
      ],
      "metadata": {
        "id": "j-hLm5PkIUV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚙️ Setup"
      ],
      "metadata": {
        "id": "acz0xuPCIuf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain openai watermark"
      ],
      "metadata": {
        "id": "-_nbErEgIzPk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark -a \"Sudarshan Koirala\" -vmp langchain,openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQPBfKScIzA5",
        "outputId": "eb749a2b-0915-421a-ee21-b8848c3499b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Sudarshan Koirala\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "langchain: 0.0.200\n",
            "openai   : 0.27.8\n",
            "\n",
            "Compiler    : GCC 9.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.15.107+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "GEtJsbNWI-Td"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get your openai api key from https://platform.openai.com/account/api-keys 🔑\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdDo3MqtJAuV",
        "outputId": "946e7ec4-b595-45ad-f530-5d4839907b1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples"
      ],
      "metadata": {
        "id": "V37hLI9UlYBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1 from OpenAI documentation"
      ],
      "metadata": {
        "id": "NLpzC_KKfzVP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5kkugVoH0Tv",
        "outputId": "1642b128-4447-4966-8519-cbaf0f3f1af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7Rca0O4WJ6fhY4vQkUVWZ4NPMDek5\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1686817512,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The current weather in Boston is sunny and windy with a temperature of 72 degrees.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 69,\n",
            "    \"completion_tokens\": 17,\n",
            "    \"total_tokens\": 86\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)\n",
        "\n",
        "# Step 1, send model the user query and what functions it has access to\n",
        "def run_conversation():\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}],\n",
        "        functions=[\n",
        "            {\n",
        "                \"name\": \"get_current_weather\",\n",
        "                \"description\": \"Get the current weather in a given location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                        },\n",
        "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                    },\n",
        "                    \"required\": [\"location\"],\n",
        "                },\n",
        "            }\n",
        "        ],\n",
        "        function_call=\"auto\",\n",
        "    )\n",
        "\n",
        "    message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    # Step 2, check if the model wants to call a function\n",
        "    if message.get(\"function_call\"):\n",
        "        function_name = message[\"function_call\"][\"name\"]\n",
        "\n",
        "        # Step 3, call the function\n",
        "        # Note: the JSON response from the model may not be valid JSON\n",
        "        function_response = get_current_weather(\n",
        "            location=message.get(\"location\"),\n",
        "            unit=message.get(\"unit\"),\n",
        "        )\n",
        "\n",
        "        # Step 4, send model the info on the function call and function response\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"What is the weather like in boston?\"},\n",
        "                message,\n",
        "                {\n",
        "                    \"role\": \"function\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        return second_response\n",
        "\n",
        "print(run_conversation())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Example 2 (Sum of two numbers)"
      ],
      "metadata": {
        "id": "zUlZSnmWKdrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets define a function\n",
        "def get_addition(number1,number2):\n",
        "    \"\"\"Get the sum of two numbers \"\"\"\n",
        "    return str(number1+number2)"
      ],
      "metadata": {
        "id": "q3IFXZ7gb6R1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions: A list of functions the model may generate JSON inputs for.\n",
        "# name: string; Required; The name of the function to be called.\n",
        "# description: string; Optional; The description of what the function does.\n",
        "# parameters; object; Optional; The parameters the functions accepts, described as a JSON Schema object.\n",
        "functions = [\n",
        "        {\n",
        "            \"name\": \"get_addition\",\n",
        "            \"description\": \"Get the addition of two numbers\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                        \"number1\": {\n",
        "                            \"type\": \"integer\",\n",
        "                            \"description\": \"The first number, e.g. 1\",\n",
        "                        },\n",
        "                        \"number2\": {\n",
        "                            \"type\": \"integer\",\n",
        "                            \"description\": \"The second number, e.g. 1\",\n",
        "                        },\n",
        "\n",
        "                    },\n",
        "                \"required\": [\"number1\", \"number2\"],\n",
        "            },\n",
        "        }\n",
        "    ]"
      ],
      "metadata": {
        "id": "q0YHKoiKKDxs"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: send model the user query and what functions it has access to\n",
        "# functions: A list of functions the model may generate JSON inputs for.\n",
        "# function_call: Controls how the model responds to function calls.\n",
        "# \"auto\" means the model can pick between an end-user or calling a function.\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What's the sum of 5 and 7?\"}],\n",
        "    functions=functions,\n",
        "    function_call=\"auto\",\n",
        ")\n",
        "\n",
        "message = response[\"choices\"][0][\"message\"]"
      ],
      "metadata": {
        "id": "zuNMXtS5L8dj"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP0v6yY-NJLb",
        "outputId": "0dc40065-2ead-45fa-bf5f-9ae0ebea39ce"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7fa0843e91c0> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": null,\n",
              "  \"function_call\": {\n",
              "    \"name\": \"get_addition\",\n",
              "    \"arguments\": \"{\\n  \\\"number1\\\": 5,\\n  \\\"number2\\\": 7\\n}\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2, check if the model wants to call a function\n",
        "if message.get(\"function_call\"):\n",
        "        function_name = message[\"function_call\"][\"name\"]\n",
        "        arguments = json.loads(message[\"function_call\"][\"arguments\"])\n",
        "\n",
        "        print(arguments)\n",
        "\n",
        "        number1=arguments[\"number1\"]\n",
        "        number2=arguments[\"number2\"]\n",
        "\n",
        "function_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "i8_1og7CNL_G",
        "outputId": "de753327-cc9c-416c-9d6b-4cf506423f6a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'number1': 5, 'number2': 7}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_addition'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3, call the function\n",
        "function_response = get_addition(\n",
        "            number1,\n",
        "            number2,\n",
        "        )"
      ],
      "metadata": {
        "id": "phST1w85Nlkr"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "G2FA0_hgOBD8",
        "outputId": "b86a96f5-b3df-4032-8d5d-71e852ec1ef1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'12'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4, send model the info on the function call and function response\n",
        "second_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is the sum of 5 and 7\"},\n",
        "        message,\n",
        "        {\n",
        "            \"role\": \"function\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": function_response,\n",
        "        },\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "0SXss-uKQmwW"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6ETa5_kQ9u_",
        "outputId": "ae4ee4c4-ecc7-4a85-e888-0d414c24002d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7Rdp1ONVOF6B9nYmpm9z4m2qfD4xf at 0x7fa08d50db70> JSON: {\n",
              "  \"id\": \"chatcmpl-7Rdp1ONVOF6B9nYmpm9z4m2qfD4xf\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1686822287,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"The sum of 5 and 7 is 12.\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 52,\n",
              "    \"completion_tokens\": 12,\n",
              "    \"total_tokens\": 64\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4, send model the info on the function call and function response\n",
        "second_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is the sum of 10 and 7\"},\n",
        "        message,\n",
        "        {\n",
        "            \"role\": \"function\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": function_response,\n",
        "        },\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "0iIpCoduRB-x"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPibqNJicdii",
        "outputId": "cf9fdc20-5927-4350-ae7c-83f929151906"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7RdpRHJBApiv8Rcj81GgaUH7umZZ4 at 0x7fa08d3b39c0> JSON: {\n",
              "  \"id\": \"chatcmpl-7RdpRHJBApiv8Rcj81GgaUH7umZZ4\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1686822313,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"The sum of 10 and 7 is 17.\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 52,\n",
              "    \"completion_tokens\": 12,\n",
              "    \"total_tokens\": 64\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 3 (Web surfing (kinda chatgpt plugin))\n",
        "- `gpt-3.5-turbo-0613` includes the same function calling as GPT-4"
      ],
      "metadata": {
        "id": "oUkfqo1-cuEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install duckpy"
      ],
      "metadata": {
        "id": "K0QCt0lPcgvh"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from duckpy import Client"
      ],
      "metadata": {
        "id": "PiHuvQBodtPG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duckduckgo_client = Client()"
      ],
      "metadata": {
        "id": "nAo63eUXd0BR"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_api(input):\n",
        "    output = duckduckgo_client.search(input)\n",
        "    return str(output)"
      ],
      "metadata": {
        "id": "PCJ7B34Mdygn"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_conversation():\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Who is the winner of Champions League 2023?\"}],\n",
        "        functions=[\n",
        "            {\n",
        "                \"name\": \"search_api\",\n",
        "                \"description\": \"Search information from online\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"input\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Input query\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"input\"],\n",
        "                },\n",
        "            }\n",
        "        ],\n",
        "        function_call=\"auto\",\n",
        "    )\n",
        "\n",
        "    message = response[\"choices\"][0][\"message\"]\n",
        "    print(message)\n",
        "\n",
        "    # Step 2, check if the model wants to call a function\n",
        "    if message.get(\"function_call\"):\n",
        "        function_name = message[\"function_call\"][\"name\"]\n",
        "\n",
        "\n",
        "        # Step 3, call the function\n",
        "        # Note: the JSON response from the model may not be valid JSON\n",
        "        function_response = search_api(\n",
        "            input = eval(message[\"function_call\"][\"arguments\"]).get('input')\n",
        "        )\n",
        "\n",
        "        # Step 4, send model the info on the function call and function response\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"Who is the winner of Champions League 2023?\"},\n",
        "                message,\n",
        "                {\n",
        "                    \"role\": \"function\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        return second_response\n",
        "\n",
        "print(run_conversation())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wro4g_R9dc3x",
        "outputId": "6cd56910-4da4-4a07-ed04-468e9e73661e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": null,\n",
            "  \"function_call\": {\n",
            "    \"name\": \"search_api\",\n",
            "    \"arguments\": \"{\\n  \\\"input\\\": \\\"winner of Champions League 2023\\\"\\n}\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"id\": \"chatcmpl-7Re1VmAQZJDRfLxJL6aDLFagLWODg\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1686823061,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The winner of the UEFA Champions League in 2023 was Manchester City. They defeated Inter Milan 1-0 in the final, which took place at Istanbul's Atat\\u00fcrk Olympic Stadium on June 10, 2023.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 2525,\n",
            "    \"completion_tokens\": 48,\n",
            "    \"total_tokens\": 2573\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Examples\n",
        "1. [How to use functions with a knowledge base](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb)\n",
        "2. [How to call functions with chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb)\n",
        "3. [LangChain Tools as OpenAI functions](https://python.langchain.com/en/latest/modules/agents/tools/tools_as_openai_functions.html)\n",
        "4. [Langchain OpenAI Function Agent](https://github.com/hwchase17/langchain/blob/master/docs/modules/agents/agents/examples/openai_functions_agent.ipynb)"
      ],
      "metadata": {
        "id": "ZAkPnVNqf8wv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9LcUOQi2pqdW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}